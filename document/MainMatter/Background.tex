\chapter{Estado del Arte}\label{chapter:state-of-the-art}
El proceso de investigaci\'on para formar un flujo de Aprendizaje Autom\'atico requiere una experemintaci\'on variada donde se combinan d\'simeles t\'ecnicas como redes neuronales, clasificadores supervistados, algoritmos de agrupamientos entre otras. Adem\'as por cada selecci\'on de las anteriores se debe optimzar para cada una los hiperpar\'ametros adecuados.

El aprendizje de m\'aquina automatizado es un campo cada vez m\'as creciente cuyo objetivo es encontrar flujos de Aprendizajes Autom\'aticos que sean \'optimos respecto a una m\'etrica de evaluaci\'on y se adapten a distintos escenarios. Los estudios recientes han llevado a la creaci\'on de sistemas de AutoML  con espacios de b\'usqeudas cada vez m\'as complejos y mejores t\'ecnicas de selecci\'on y modelos de hiperpar\'ametros.

Con el uso de un sistema AutoML el investigador ya no tiene que crear el flujo de Aprendizaje Autom\'atico manualmente; puede dedidcarse a otras tareas como el adecuado preprocesamiento de los datos o ingenier\'ia de caracter\'istcas, no obstante, el proceso de automatizaci\'on viene con un costo. Cuando al cient\'ifico no le es suficiente con que el sistema produzca resultados relevantes y desea un mayor control sobre los flujos producidos tal que tengan un buen desempe\~no con respecto a alguna m\'etrica adicional, los sistmeas AutoML dejan de ser de \'utiles pu\'es en el estado del arte actual del Aprendizaje Automatizado no existe el soporte para esto.

En la secci\'on \ref{proposal:automl} se  hace un estudio del estado del arte en AutoML. Luego en la secci\'on \ref{proposal:moo} se estudia los diferentes paradigmas de Optimizaci\'on Multiobjetivo y se muestran diferentes propuestas de cada uno. Finalmente en la secci\'on \ref{proposal:mooautoml} se analiza casos conocidos donde al problema AutoML se le ha aplicado optimizaci\'on multiobjetivo.

\section{Aprendizaje de M\'aquina Automatizado}\label{proposal:automl}
% Que es AutoML
El Aprendizaje de M\'aquina Automatizado (Automated Machine Learning, AutoML) consiste en la generaci\'on autom\'atica de flujos, algoritmos o par\'amteros que resuelven un problema determinado minimizando la dependencia del usuario. 

Actualmente los sistemas AutoML se pueden en separar en dos conjuntos dependiendo del problema a resolver. Se encuentran los sistemas orientados a aprendizaje profundo conocido como B\'usqueda de Arquitecturas Neuronales (\textit{Neural Arquitectural Search}, NAS) y  Auto-ML basado en selecci\'on y combinaci\'on de modelos que pueden resolver el problema NAS o no. El segundo conjunto intenta resolver el problema de combinaci\'on, selecci\'on y optimizaci\'on de hiperpar\'ametros (\textit{Combined Algorith Selection and Hyperparameter Optimization}, CASH) acuñado por Auto-Weka (\cite{thornton2013auto}). M\'as formalmente:
\begin{definition}
    Sea $A = \{a^1, ..., a^k\}$  un conjunto de algoritmos con espacios de configuraci\'on asociados $\Lambda^1, ..., \lambda^k$.
    Sea $D$ un conjunto de datos  que se divide en $\{D_{t}^{(1)},..., D_{t}^{(k)}\}$ y $\{D_{v}^{(1)},..., D_{v}^{(k)}\}$ 
    tal que $\forall i, 1 \leq i \leq k$ se cumple que $D_{t}^{(i)} = D \setminus D^{(i)}_{v}$
    El problema CASH se define como el computo de:
    \begin{equation*}
        a^*_{\lambda^*} \in argmin_{a^{(j)} \in A, \lambda \in \Lambda^{(j)}} \frac{1}{k} \sum^{k}_{i = 1}\mathcal{L}(a^(j)_\lambda, D^{(i)}_t, D^{(i)}_v)
    \end{equation*}
    Donde $\mathcal{L}(a, D_t, D_v)$ es la funci\'on de p\'erdida al ser entrenado en $D_t$ y evaluado en $D_v$.
\end{definition}


% El objetivo es transferir el problema de combinaci\'on, selcci\'on y optimizaci\'on de hiperpar\'ametros(\textit{Combined Algorithm Selection and Hyperparameter Optimization}, CASH por sus siglas en ingl\'es) del investigador al sistema, permitiendole a este enfocarse en otras tareas como la validaci\'on de los datos o ingenier\'ia de caracter\'istcas.

En el campo del Aprendizaje de M\'aquina Automatizado han habido numerosas propuestas de distintos dominios:
\begin{itemize}
    \item Optimizaci\'on Bayesiana(\cite{hutter2019automated})
    \item Programaci\'on Evolutiva (\cite{chen2018autostacker})
    \item B\'usqueda Aleatoria 
    \item Aprendizaje por Refuerzo
    \item M\'etodo de Gradiente
    \item Modelos Constructivos
    \item Monte Carlo
\end{itemize}

\subsection{Optimizaci\'on Bayesiana}
Las propuestas basadas en optimizaci\'on bayesiana est\'an divididas en dos componentes principales: un modelo estad\'istico bayesiano para modelar la funci\'on objetivo, y una funci\'on de adquisici\'on que dirige la b\'usqueda en el espacio. Esos sistemas utilizan el modelo estad\'istico para seleccionar el mejor candidato a evaluar. Luego de la evaluaci\'on se actualiza el modelo y se itera la b\'usqueda.

\paragraph{Auto-WEKA (\cite{thornton2013auto})} Utiliza como algoritmos de aprendizaje las m\'aquinas WEKA, una popular biblioteca de Aprendizaje Autom\'tico en Java. Presenta dos optimizadores bayesianos, una propuesta de configuraci\'on secuencia de Algortimos basados en Modelos (SMAC por \cite{hutter2011sequential}) y un estimador de Parzen con estrucutra de arbol (TPE por \cite{bergstra2011algorithms}), ambos se ejecutan en paralelo y se retorna la funci\'on con menor error en validaci\'on de entre todas las descubiertas.

\paragraph*{Auto-skelearn (\cite{feurer2015efficient})} Utiliza como biblioteca de aprendizaje autom\'atico a scikit-learn (\cite{pedregosa2011scikit}) y extiende la propuesta de AutoWEKA  introduciendo mejoras como la inclusi\'on de un paso de meta-aprendizaje que reduce el espacio de b\'usquda aprendiendo de modelos que funcionaron bien en conjuntos de datos similares y luego un paso de selecci\'on de ensemblers que le permite reusar los flujos de Aprendizaje de M\'aquina que tuvieron mejor rendimiento. 

\paragraph*{HyperOpt-Sklearn (\cite{komer2014hyperopt})} Similar a Auto-Skelearn con respecto a la bibliteca de aprendizaje subyacente, scikit-learn, utiliza Hyperopt (\cite{bergstra2013hyperopt}) para describir el espacio de b\'usqueda. Provee una infterfaz de optimziaci\'on que distingue un espacio de configuraciones y una funci\'on de evaluaci\'on que asigna valores de p\'erdida reales a puntos dentro de dicho espacio. Hyperopt requiere que el espacio est\'e definido como una distribuci\'on de probabilidad, permitiendo una codficacio\'on m\'as expresiva de las intuiciones de los expertos con respecto a los valores de los hiperpar\'ametros. Utiliza SMBO (\textit{Sequential Model-based Bayesian Optimization}), consideraando este algoritmo como una componente intercambiable con el fin de que cualquier t\'ecninca de b\'usqueda pueda ser utilizada con cualquier problema de b\'usqueda.

      \paragraph*{Auto-Keras (\cite{jin2018efficient})} Un sistema de Auto-ML enfocado en resolver el problema NAS. Est\'a basado en la biblioteca Keras de Python, utilizada para crear redes neuronales.  La idea prinicipal de esta propuesta es explorar el espacio mediante la transformaci\'on de redes, utilizando un algorimto de Optmizaci\'on Bayesiana eficiente. Dichas transformaciones permiten generar redes manteniendo las configuraciones alcanzadas con entrenamientos anteriores, disminuyendo el uso de los recursos de c\'omputo. Auto-Keras a nivel t\'ecnico est\'a estructurado para el uso eficiente de la memoria y la ejecuci\'on en paralelo sobre el CPU y el GPU.

      \paragraph*{autogxgboost (\cite{thomas2018automatic})} Se cat\'aloga como un sistema AutoML \textit {single-learner} debido a que solo utiliza un algoritmo de aprendizaje y solamente optimiza los hiperpar\'ametros para este utilizando optimizaci\'on bayesiana. Requiere que el algoritmo sea un metodo de aumento de gradiente con \'arboles (\textit{Gradient Boosting with Trees}, GBT) como \textit {xgboost} (\cite{chen2016xgboost}) debido a su prometedor rendimiento con los param\'etros adecuados.   
    
\subsection{Programaci\'on Evolutiva}
     Los sistemas AutoML bas\'ados en programaci\'on evolutiva funcionan creando una poblaci\'on inicial de flujos v\'alidos para luego seleccionar los de mejor rendmiento respecto a cierta m\'etrica y los mejores son utilizados para crear la poblaci\'on de la pr\'oxima iteraci\'on. Las propuestas difieren principalmente en como modelan el espacio de b\'usqueda y que estrategias usan para crear los nuevos individuos.
     \paragraph*{TPOT (\cite{pmlr-v64-olson_tpot_2016})} Utilzando algormiso de aprendizaje de la biblioteca scikit-learn (\cite{pedregosa2011scikit}) junto con el algoritmo xgboost (\cite{chen2016xgboost}), es uno de los sistemas AutoML evolutivos m\'as reconocidos. Cada algoritmo de Aprendizaje Autom\'atico a su disposici\'on se le considera un operador, adem\'as de tener un operador especial de cruce. Permite tener varias copias del dataset y aplicar operadores sobre ellos simult\'aneamente para luego recombinarlos y crear flujos con los operadores que hayan tenido mejor rendimiento. TPOT adem\'as realiza una b\'usqueda multiobjetivo sobre las soluciones encontradas utilizando NSGA-II (\cite{deb2002fast}) optimzando maximizar exactitud (\textit{accuracy} en la literatura) y minimizando la cantidad de operadores aplicados sobre los flujos de ML por un tema de simplicidad y evitar el sobreajuste a los datos.

     \paragraph*{RECIPE (\cite{de2017recipe})} Utiliza programaci\'on gen\'etica basado en gram\'aticas (\textit{Grammar Genetic Programming}, GGP) para generar sus flujos. El sistema recibe como entrada un conjunto de datos y una gram\'atica libre del contexto (CFG), que utiliza para formar una poblac\'on inicial de flujos. Luego a partir de los mejores individuos de la poblacion le aplican operadores de mutaci\'on y cruzamiento que fuerzan el cumplimiento de las reglas de producci\'on de la gram\'atica para generar una nueva poblaci\'on. Utiliza como base la bibliotea scikit-Learn (\cite{pedregosa2011scikit}).
 

     \paragraph{AutoGOAL (\cite{estevez2020solving})} Utiliza una Grama\'atica Probabl\'istca Libre del Contexto (\textit{Probabilistic Context-Free Grammars}) para modelar el espacio de b\'usqueda y Evoluci\'on de Gram\'atica  Probabil\'istica (\textit{Probabilistic Grammatic Evolution}, \cite{megane2021probabilistic}) para construir las soluciones. Tiene integrados muchos algorimtos de aprendizaje de diversas bibliotecas de Python y su generalidad permite abarcar problemas de cualquier tipo, incluido problemas de procesamiento de lenguage natural, donde cuenta con algoritmos de pre-procesadores de datos.

\subsection{B\'usqueda Aleatoria}
Consiste en la exploraci\'on del espacio de b\'usqueda, ya sea de forma secuencial o en paralelo mediante la selecci\'on de soluciones aleatorias. Este m\'etodo es utilizado muchas veces como comparaci\'on frente a estrategias m\'as avanzadas.

\paragraph{NASH (\cite{wei2016network})} Neural Arquitecture Search by Hillclimbing es una propuesta de soluci\'on al problema NAS.
        Partiendo de una red aleatoria o predeterminada le aplica morfismos de red para obtener  nuevas redes ``vecinas''. Se eval\'uan utilizando una funci\'on de evaluaci\'on y la que tenga mejor rendimiento se toma como principal y se reptie el proceso. La estrategia de hill climbing que sigue elimina la necesidad de rentrenar las nuevas redes desde cero.

        \paragraph{H20 AutoML (\cite{ledell2020h2o})} Disponible en varios lenguages, utiliza la biblioteca H20 (\cite{boehmke2019hands}), una biblioteca de aprendizaje autom\'atico. Construye multiples modelos con diferentes juegos de hiperpar\'ametros seleccionados aleatoriamente en base de ciertas heur\'isticas. En funci\'on de la disponibilidad de recursos de c\'omputo la b\'usqueda se detiene y los mejores modelos se utilizan para construir un ensemble.

        \paragraph{TransmogrifAI (\cite{tovbin93meet})}  Ideado con el objetivo de tener un buen rendimiento en datasets grandes, fue dise\~nado para ejecutarse sobre Apache Spark. Encapsula cinco componentes del proceso de aprendizaje autom\'atico en diferents pasos:
        \begin{enumerate}
            \item Realiza un preprocesamiento de los datos donde obliga al cient\'ifico a especificar un esquema y establecer un sistema de tipos sobre estos. Transmogrif los analiza siendo capaz de inferir el tipo de algunos.
            \item Aplica ingenier\'ia de caracater\'isticas automatizada: eventualmente los datos, sin importar del tipo que sean, deben tener representaci\'on n\'umerica adecuada (todo un arte de la ciencia de datos).
            \item Hace una validaci\'on de las caracter\'isticas para mitigar  la probable explosi\'on de dimensionalidad ocurrida en el paso anterior y los problemas que ello acarrea.
            \item Resuelve el problema de selecci\'on autom\'atica de modelos ejecutando un torneo de varios algoritmos de Aprendizaje Autom\'atico, y escoge el mejor seg\'un el error de validaci\'on promedio.
            \item En cada uno de los pasos anteriores se ejecuta adem\'as un paso subyacente de optimizci\'on de hiperpar\'ametros, contrario a  muchos sistemas AutoML que solo optimizan solamente para el modelo soluci\'on. 
        \end{enumerate}
        %donde la b\'usqueda se realiza sobre el espacio de las transformaciones de caracter\'isticas que son posibles en funci\'on de los datos utilizados.


\subsection{Aprendizaje por Refuerzo}
El aprendizaje por refuerzo, como estrategia de b\'usqueda consiste en entrenar un agente que realiza modificaciones sobre una soluci\'on con el objetivo de maximizar una recompensa que depende del rendimiento de dicha soluci\'on. Est\'a estrategia es utilizada mayormente en sistemas AutoML que buscan resolver el problema NAS, donde el agente puede realizar acciones como a\~nadir, remover, o modificar una capa o sus hiperpar\'ametros. Las propuestas difieren seg\'un el dise\~no del agente.

        % Para la representaci\'on de NAS como un problemam de aprendizaje por refuerzo, la generaci\'on de una rquitectura se considera como una acci\'on de un agente siendo el esapcio deacciones id\'entico al espacio de b\'usqueda. La recompenza del agente se basa en el rendimiento de las redes entrenadas. Las propuestas difieren en como se represente la politica del agente y como la optimizan.

\paragraph*{EAS (\cite{cai2018efficient})} Effiecient Arquitectural Search utiliza un meta-controlador basado en aprendizaje por refuerzo (\textit{Reinforcment Learning}, RL, \cite{kaelbling1996reinforcement}) y el algorimto REINFORCE (\cite{williams1992simple}) para actualizarlo. En general, este sistema modela el proceso de dise\~no autom\'atico de arquitecutras como un proceso de toma de decisiones secuencial, donde el estado de la red actual y la actuaci\'on es la operaci\'on de transformaci\'on correspondiente. Despue\'es de una cantidad determinada de pasos, la arquitectura resultante es evaludada para obtener la se\~nal de recompensa, que luego es utilizada para actualizar el meta-controlador, maximizando la validaci\'on.

        \paragraph*{NASNet (\cite{zoph2018learning})} Utiliza aprendizaje por refuerzo para la construcci\'on \'optima de una red neural para cualquier conjunto de im\'agenes. La contribuci\'on clave de esta propuesta es que el diseño del espacio de b\'usqueda permite construir la arquitectura en un dataset peque\~no y luego transferir los conocimientos para el entrenamiento de un set m\'as grande, aligerando el costo computacional de aplicarlo directamente sobre un dataset grande.


% \section{M\'etodos de Gradiente}
% Los m\'etodos que utilzan esta estraetigan buscan calcular la direcci\'on del gradiente tal que se mejore el rendimiento de la soluci\'on inicial y evaluar nuevas soluciones en la vecindad de dicha direcci\'on. Cuando se tiene un espacio de b\'usqueda diferenciable el gradiente se puede calcular de forma exacta.

    % \paragraph*{DARTS} eso

\subsection{Modelos Constructivos}
Estos m\'etodos exploran el espacio de b\'usqueda con una forma estructurada pues se definen de antemano los posibles modelos y formas de combinarlos. Se establece un orden de evaluaci\'on de las soluciones y la b\'usqueda finaliza cuando todo el espacio ha sido explorado. Esta estrategia es \'util cuando el espacio de b\'usqueda es peque\~no y consta de modelos bien definidos, variados y con un buen rendimiento.

\paragraph{AutoGluon (\cite{erickson2020autogluon})} Realiza procesamiento de datos avanzados, aprendizaje profundo y ensamblaje de modelos multicapa. Reconoce autom\'aticamente el tipo de datos de cada columna para un procesaminto de datos robustos. Construye un ensemble multicapa  tomando como entrada la instancia de cada uno de los tipos de modelos predefinidos. Los modelo se entrena de forma secuencial y se a\~naden al ensemble. Para finalizar, se realiza un proceso de post-optimizaci\'on para destilar el ensemble resultante en un modelo m\'as peque\~no con rendimiento similar.

\subsection{Monte Carlo}
 Esta estrategia se emplea en espacios de b\'usquedas jer\'arquicos para explorar eficientemente el \'arbol que describe todas las  posibles soluciones. En cada iteraci\'on se deciende por una rama del \'arbol hasta llegar a un nodo hoja, el camino representa una posible soluci\'on. Como todo algoritmo de MonteCarlo requiere de una definici\'on adecuada de una funci\'on que permita un balance entre exploraci\'on y explotaci\'on. Esta estrategia require un espacio de b\'usequda donde las decisiones m\'as importantes esten al principio en el \'arbol para ser efectiva

 \paragraph{ML-Plan (\cite{mohr2018ml})} Un sistema novedoso basado en redes de tareas jer\'arquicas (HTN, \cite{erol1994umcp}). La b\'usqueda es aleatoria, construyendo flujos parciales junto con un mecanismo que evita el sobreajuste. Cuenta con con dos tipos de algoritmos:  preprocesadores de datos y de aprendizaje. Sus flujos son un par compuestos por un procesador parametrizado y por un algoritmo de aprendizaje.
    


\section{Optimizaci\'on Multiobjetivo}\label{proposal:moo}
Optimizaci\'on Multiobjetivo es la rama de la Ciencia y la Matem\'atica que se dedica a optimizar varias funciones objetivos sim\'ultaneamente. Es relativamente nueva y un campo activo de investigaci\'on.

Ha encontrado abundante campo en la ingenier\'ia y la econom\'ia donde muchas veces suelen existir objetivos opuestos. Exsiten muchos aplicaciones en la actualidad que se benefician de aplicar optimziaci\'on multiobjetivo, por ejemplo:
\begin{itemize}
    \item Lograr el balance entre energ\'ia producida y combustible utilizado por una termoel\'ectrica (\cite{shirazi2012thermal} y \cite{shirazi2014thermal}).
    \item El dise\~no \'optimo de una estructura como la configuraci\'on de gabinete de control (\cite{pllana2019customizing}) o una granja solar (\cite{ganesan2013hypervolume}).
    \item La distribuci\'on adecuada de recursos de radio para satisfacer eficientemente el requerimiento de sus usuarios (\cite{bjornson2013optimal}).
    \item La inspecci\'on de infraestructura compleja es costosa, y muchas veces no es factible cubriendo el \'area completa. Se busca optimizar la covertura mientras se minimizan los costos (\cite{ellefsen2017multiobjective}).
\end{itemize}

\begin{definition}{Optimizaci\'on Multibojetivo:}
    \label{background:def:moo}
     Dado $m$ funciones objetivos: $f_1: \mathcal{X} \rightarrow \mathbb{R}, ..., f_m: \mathcal{X} \rightarrow \mathbb{R}$ que dado un vector en el espacio de decisi\'on $\mathcal{X}$ es transformado en un valor de $\mathbb{R}$. Se define el PMO como:
    \begin{equation*}
        \min f_1(x), ..., f_m(x), x \in \mathcal{X}
    \end{equation*}
\end{definition}

Cuando se optimizan varias funciones, la mejor soluci\'on  no es un escalar, sino un vector y no necesariamente \'unico; pues al haber m\'as de dos medidas de evaluaci\'on un vector puede ser superior a otro sobre ciertas componentes pero no en todas. Un vector se dice mejor o que \textit{Pareto domina} a otro cuando es superior en al menos una componente, y no peor en las restantes. Se conoce formalmente en la literatura como \textit{Pareto dominaci\'on}.
\begin{definition}{Pareto Dominaci\'on:}
    \label{background:def:domintation}
    Dados dos vectores en el el espacio objetivo, $x \in \mathbb{R}^m$ y $z \in \mathbb{R}^m$, se dice que $x$ Pareto domina a $z$ (i.e. $x \prec z$), si y solo si:
    \begin{equation*}
        \forall i \in \{1, ..., m\}: x_i \leq z_i \text{ y } \exists j \in \{1, ..., m\}: x_j < z_j
    \end{equation*}
\end{definition}

Cuando se tiene un subconjunto de vectores, dentro de todo el espacio,  a los que ning\'un otro vector domina, se le  llama Frente de Pareto y es el conjunto soluci\'on del problema multiobjetivo.

\begin{definition}
    \textit{Frente de Pareto}: Todos los vectores $x$ del espacio objetivo $\mathcal{Y}$ tal que no exista un vector $y \in \mathcal{Y}$ que \textit{Pareto domine} a $x$.
    \begin{align*}
        \mathcal{P} = \{x| x, y \in \mathcal{Y}, \neg \exists y \prec x \} 
    \end{align*}
\end{definition}

%TODO:
%Hablar sobre a priori, interactivo y a posteriori en la optimizacion multi objetivo?


El problema multiobjetivo se ha intentado resolver utilizando tres enfoques de diferentes campos de la Computaci\'on y la Matem\'atica:
\begin{enumerate}
    \item T\'ecnicas de Escalarizaci\'on.
    \item M\'etodos Num\'ericos.
    \item Algoritmos Evolucionarios.
\end{enumerate}


% Añadir problemas que se hayan resulto con multiobjetivo
% El objetvio es mostrar lo mucho que se ha usado multiobjetivo 
% Y lo poco que se ha utilizado en automl
% Decir que lo vamos a probar 

\subsection{T\'ecnicas de Escalarizaci\'on }

Las t\'ecincas de escalarizaci\'on han sido las m\'as utilizadas para resolver el problema multiobjetivo (\cite{miettinen2012nonlinear}). Estas t\'ecnicas consisten en agregar funciones objetivos o  reformularlas como restricciones en una sola funci\'on sobre la cual se aplica un m\'etodo de optimizaci\'on est\'andar de un solo objetivo. La nueva funci\'on objetivo adem\'as se parametriza con un vector de pesos, que dependiendo de sus valores resulta en un punto distinto del frente de pareto.
\begin{enumerate}
    \item Linear Weighting: La t\'ecnica m\'as conocida, todas las funciones objetivos se combinan en una sola, y a cada una se le asigna un peso distinto.
    \begin{equation*}
        \min \sum w_i f_i(x), \space x \in X
    \end{equation*}
    Se garantiza que una soluci\'on de esta nueva funci\'on objetivo siempre est\'a sobre el frente de Pareto  y si este es convexo se puede hallar cualquier punto de este con el correcto vector de peso(\cite{emmerich2018tutorial}). El problema yace cuando el frente de Pareto tiene forma c\'oncava donde \textit{Linear Weighting} resulta insuficiente por no ser capaz obtener los puntos de esta secci\'on del frente.

    \item $\epsilon$-constrain: Se selecciona una funci\'on objetivo como principal y las dem\'as se establecen como restricciones de esta tal que sean menor que cierto $\epsilon_i$  por cada funci\'on objetivo.
    \begin{align*}
            \min  f_1(x), \space x \in X  & \text{, sujeto a:}   \\
            g_i(x) \leq \epsilon_i & \quad  \forall i, 2 \leq i \leq n
    \end{align*}
    Esta enfoque presenta dos dificultades principales: la valores de los $\epsilon_i$, para una adecuada selecci\'on requiren conocimiento previo del frente de Pareto y al igual que \textit{Linear Weighting}, no es capaz de detectar soluciones en las partes c\'oncavas del frente (\cite{emmerich2018tutorial}).

    % TODO: Que condicion cumple los pesos de Chebychev
\item Chebychev Distance (CSP): Se establece un punto de referencia $z^*$ y se utiliza la distancia de Chebychev de los vectores objetivos hacia este como funci\'on objetivo utilizando un vector de pesos $\lambda \in \mathbb{R}^m_{\prec 0}$, donde $\mathbb{R}^m_{\prec 0} = \{x | x \in \mathbb{R}^m, x \prec 0 \}$. 
    \begin{align*}
        \min \quad \max_{i \in {1,...,m}} \lambda_i |f_i(x) - z^*_i|, x \in X 
    \end{align*}
    CSP dado un punto de referencia y vector de pesos adecuados puede encontrar cualquier punto del frente de Pareto, no importa su forma (\cite{emmerich2018tutorial}).
\end{enumerate}

Recientemente escalarizaci\'on ha encontrado uso de algoritmos gene\'eticos por descomposici\'on para optener muestras distintas del frente de pareto.  En \cite{paria2020flexible} se propone un algorimto capaz de muestrear un area determinada del frente de Pareto utilizando una estrategia basada en escalarizaci\'on aleatoria.


\subsection{Algoritmos Num\'ericos}

% TODO: Es esto verdad?
En principio todos los algoritmos de escalarizaci\'on se pueden resolver utilzando m\'etodos n\'umericos. Adem\'as existen otros m\'etodos  que intentan resolver el problema haciendo cumplir las condiciones de Karush-Kuhn-Tucker (KKT) definidas por \cite{kuhn2014nonlinear}.

La idea va de encontrar al menos una soluci\'on al sistema de ecuaciones creado tras intentar resolver el problema KKT. Luego se utilizan m\'etodos de continuaci\'on y homotop\'ia para añadir al conjunto soluci\'on soluciones cercanas a esta. 
Este tipo de enfoque no es ideal para espacios de b\'usqueda complejos pues requiere que las soluciones satisfagan las condiciones de convexidad local y diferenciabilidad. se puede obtener mas infomraci\'on en \cite{hillermeier2001nonlinear} y \cite{schutze_et_al:DagSemProc.04461.16}.

Tambien existen otros metodos para la b\'usqueda de m\'inimos globales como \textit{T\'ecnicas de Subdivisi\'on} por \cite{dellnitz2005covering}, \textit{Optimizaci\'on Global Bayesiana} por \cite{emmerich2016multicriteria} y \textit{Optimizaci\'on de Lipschitz} por \cite{vzilinskas2013worst}. % Estas requiren de que el espacio de decisi\'on tenga una baja dimensionalidad.

Adem\'as  se investiga  m\'etodos n\'umericos que no necesiten diferenciar para su resoluci\'on utilizando t\'ecnicas de b\'usquedas directas. Se pueden encontrar ejemplos de estos algoritmos en \cite{custodio2011direct} y \cite{audet2010mesh}.

\subsection{Algoritmos Evolucionarios Multiobjetivos }

Los algorimtos gen\'eticos utilizan paradigmas extra\'idos de la naturaleza, tal como selecci\'on natural, mutaci\'on y recombinaci\'on para dirigir una poblaci\'on (o conjunto de vectores de decisi\'on) hacia una soluci\'on \'optima (\cite{back1996evolutionary}).

Los algoritmos evolucionarios multiobjetivos (MOEA) generalizan esta idea, y son diseñados para acercarse en cada iteraci\'on  al frente de Pareto. Como en este caso no existe soluci\'on \'unica, la manera de selccionar los individuos cambia fundamentalmente. Dentro de los MOEA existen tres paradigmas principales:

\begin{enumerate}
    \item \textbf{MOEA basados en el frente de Pareto}\label{background:def:MOEA}: Se identifican por dividir el proceso de selecci\'on en dos etapas. En la primera se organizan los invidiuos segu\'un su ind\'ice de dominaci\'on y se acomodan en distintos subconjuntos seg\'un la cantidad de soluciones que los dominen (e.g. un subconjunto para las soluciones a las cuales nadie domina, otro para los son dominados por alguna soluci\'on etc.). En la segunda ordenaci\'on cada subconjunto se ordena buscando que los primeros lugares sean los elementos m\'as representativos de cada subconjunto. NSGA-II (\cite{deb2002fast}) y SPEA2 (\cite{zitzler1999multiobjective}) son algoritmos de este tipo.

    \item \textbf{Basados en indicador}: Estos utilizan un indicador para calcular cuan cercano es el conjunto actual al frente de Pareto (unario), o cuanto mejora el nuevo conjunto de soluciones respecto a la iteraci\'on anterior (binario). Ejemplo de este es SMS-EMOEA (\cite{emmerich2005emo}) que suele converger al frente de Pareto con soluciones igualmente distribuidas.

    \item \textbf{Basados en descomposici\'on}: La idea principal consiste en descomponer el problema en pequeños subproblemas cada una correspondiente a una secci\'on del frente de Pareto. Por cada sub-problema se resuelve utilizando escalarizaci\'on con diferente paramtrizaci\'on. El m\'etodo de escalarizaci\'on m\'as usado en estos casos suele ser CSP debido a ser capaz de obtener cualquier punto del frente de Pareto. Ejemplo de este paradigma son MOEA/D (\cite{zhang2007moea}), NSGA-III (\cite{deb2013evolutionary}) y MOMSA (\cite{sharifi2021new}).

\end{enumerate}

% (Poner esto en alg\'un lado)
 El termino Optimizaci\'on Multiobjetivo se utiliza cuando el n\'umero de funciones objetivos son dos o tres. Para un cantidad de m\'etricas mayor se le conoce coloquialmente en la literatura como Optimizaci\'on para Muchos Objetivos o \textit{many-objective optimization} en ingl\'es, propuesto inicialmente por \cite{10.1007/978-3-540-31880-4_2}. Se hace enf\'asis en esta diferenciaci\'on pues al aumentar el n\'umero de m\'etricas a optimizar:
 \begin{enumerate}
     \item ya no es posible visualizar el frente de Pareto;
     \item la computaci\'on de indicadores o de selecci\'on para muchos algoritmos se convierte en problemas NP-duros;
     \item existe un r\'apido crecimiento de puntos no dominados, mientras mayor n\'umero de objetivos, la probabilidad de que un punto sea no dominado en un set con distribuci\'on normal tiende exponencialmente a 1.
 \end{enumerate}

Los algoritmos que mejor han tenido resultado en esta \'area son los algoritmos basados en descomposci\'on.


\section{AutoML y Multiobjetivo}\label{proposal:mooautoml}
% En el campo del aprendizaje de m\'aqina han habido varias investigaciones respecto a la Optimizaci\'on Multibobjetivo.  An\'alisis de curva caracter\'istca de receptor (\textit{receiver operating characteristic curve}, ROC) de \cite{everson2006multi} para calcular el costo de clasificaciones err\'oneas de un clasificador mostrando gr\'aficamente un intercambio entre los verdaderos y falsos positvos de dos o m\'as problemas de clasificaci\'on utilizando Optimizaci\'on Multiobjetivo. 
% \cite{jin2008pareto} hacen un analisis sobre la adici\'on de optimizaci\'on multibojetivo al Aprendizaje de M\'aquina. Compara los diferentes enfoques de escalarizaci\'on y algoritmos gen\'eticos.
% En el campo de configuraci\'on de algoritmos \cite{blot2016mo} introduce un busqueda iterativa local basado en multiples criterios para configurar solucionadores SAT.

Recientemente ha habido enf\'asis en la comunidad FatML (\textit{Fairness, Accountability and Transparency in Machine Learning}) sobre como optimizar utilizando una sola m\'etrica acarrea problemas que pueden ser evitados optimizando simult\'aneamente para m\'ultiples m\'etricas (\cite{barocas2017fairness}). No obstante, es escaso el estudio sobre sistemas de Aprendizaje de M\'aquina Automatizado a los que se les aplica optimizaci\'on multiobjetivo.

Definimos el problema multiobjetivo aplicado a sistemas AutoML de la siguiente manera:
\begin{definition}\label{proposal:moo-automl-problem}
    Dado un conjuntos de datos $D$ y  un conjunto de m\'etricas a evaluar $M = \{f_1, f_2, ...,f_m\}$, se espera que  un sistema AutoML $\mathcal{A}$ retorne un conjunto de flujos, algoritmos o redes $P = \{p_1, p_2, ..., p_k\}$ tal que su evaluaci\'on con respecto a las m\'etricas en $M$ sean una aproximaci\'on del frente de Pareto en el espacio objetivo $\mathcal{Y}$ .
    \begin{equation*}
        \mathcal{A}(D, M) = P  
    \end{equation*}
\end{definition}

TPOT (\cite{pmlr-v64-olson_tpot_2016}) es un ejemplo de Sistema AutoML que aplica multiobjetivo para su resoluci\'on. Despu\'es de cada iteraci\'on ordena los algoritmos utilizando NSGA-II (\cite{deb2002fast}) gu\'iandose por exactitud de las predicciones y n\'umero de operadores (i.e. algoritmos de aprendizaje). No obstante el resultado de TPOT no es un conjunto soluciones, sino la soluci\'on que mejor rendimiento tuvo durante las pruebas de validaci\'on. El uso de optimizaci\'on multiobjetivo en TPOT se utiliza principalmente como medida para evitar el sobre ajuste del modelo a los datos.

\cite{pfisterer2019multi} propone una soluci\'on al problema multiobjetivo bas\'andose en \textit{autoxgboost} (\cite{thomas2018automatic}) y utilizando  parEgo (\cite{knowles2006parego}) un sistema de escalarizaci\'on multiobjetivo utilizando CSP con un vector de peso uniforme. Luego la funci\'on restultante de aplicar escalarizaci\'on es optimizada utilizando optimizaci\'on bayesiana est\'andar de un s\'olo criterio.
El algoritmo se beneficia de un humano en el proceso de optimizaci\'on durante la b\'usqueda especifica trav\'es de restricciones a donde se quiere dirigir la b\'usqueda multiobjetivo.
Al estar basados en un sistema AutoML que utiliza un solo algoritmo, el espacio de b\'usqueda se encuentra limitado y es posble que no incluya configuraciones \'optimas.

% El estudio de optimizaci\'on en sistemas Aprendizaje de M\'aqina Automatizado es bastante escaso. Entre los sistemas AutoML que cuentan con esta caracter\'istica se encuentra es TPOT \cite{pmlr-v64-olson_tpot_2016} que optimiza mutuamente para exactitud y modelos de Aprendizaje de Maquina m\'as sencillos, no obstante estas m\'etricas est\'an fijas y el progrmador no puede modificarlas, ni a\~nadir m\'as.
% En \cite{pfisterer2019multi} se propone una adici\'on a \textit{autoxgboost} (\cite{thomas2018automatic}) para optimizar multiobjetivo utilizando un algoritmo de simple de escalarizaci\'on. Esta implementaci\'on es flexible en cuanto a m\'etricas utilizar.

% En AutoGOAL se propone la adici\'on de optimizar para varios objetivos utilizando un algorimto gen\'etico que est\'an demostrados que son resistentes a la forma del frente de Pareto. Los objetivos seri\'ian definidos por el usuario y la respuesta ser\'ia un conjunto de flujos de ML que estuvieran en el frente de Pareto.


