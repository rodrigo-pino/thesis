\chapter{Estado del Arte}\label{chapter:state-of-the-art}
El proceso de investigaci\'on para dise\~nar un flujo de Aprendizaje Autom\'atico requiere una experimentaci\'on variada donde se combinan m\'ultiples t\'ecnicas de aprendizaje como redes neuronales, clasificadores supervisados, algoritmos de agrupamientos, entre otras. Adem\'as por cada selecci\'on de las t\'ecnicas anteriores se deben optimizar adecuadamente los hiperpar\'ametros que la componen.

Con el uso de un sistema AutoML el investigador ya no tiene que crear el flujo de Aprendizaje Autom\'atico manualmente y puede dedicarse a realizar otras tareas como la modelaci\'on del problema, no obstante, el proceso de automatizaci\'on viene con un costo. Cuando al experto necesita m\'as que modelos que produzcan resultados relevantes los sistemas AutoML actuales se tornan insuficientes pues no posee el suficiente control para comunicarle al sistema su intenci\'on de guiar la b\'usqueda en otros sentidos. Por ejemplo, el modelo por el que se rige un carro para conducirse aut\'onomamente debe ser lo suficientemente interpretable para que usuarios no expertos puedan entender sus decisiones.
% de controlar el espacio de decsi\'on  desea un mayor control sobre los flujos producidos tal que tengan un buen desempe\~no con respecto a alguna m\'etrica adicional, los sistmeas AutoML dejan de ser de \'utiles pu\'es en el estado del arte actual del Aprendizaje Automatizado no existe el soporte para esto.

En la secci\'on \ref{background:automl} se  hace un estudio del estado del arte en AutoML. Luego en la secci\'on \ref{background:moo} se estudia los diferentes paradigmas de Optimizaci\'on Multiobjetivo y se muestran diferentes propuestas de cada uno. Finalmente en la secci\'on \ref{background:mooautoml} se analizan casos conocidos donde al problema AutoML se le ha aplicado optimizaci\'on multiobjetivo.

\section{Aprendizaje de M\'aquina Automatizado}\label{background:automl}
% Que es AutoML
El Aprendizaje de M\'aquina Automatizado (Automated Machine Learning, AutoML) consiste en la generaci\'on autom\'atica de flujos, algoritmos o par\'ametros que resuelven un problema determinado y minimizan la dependencia del usuario. 

Actualmente los sistemas AutoML se pueden separar en dos conjuntos dependiendo del problema a resolver. Se encuentran los sistemas orientados a aprendizaje profundo que proponen resolver el problema de B\'usqueda de Arquitecturas Neuronales (\textit{Neural Arquitectural Search}, NAS) y  sistemas AutoML basado en selecci\'on y combinaci\'on; este \'ultimo puede solucionar o no el problema NAS. El segundo conjunto intenta resolver el problema de combinaci\'on, selecci\'on y optimizaci\'on de hiperpar\'ametros (\textit{Combined Algorith Selection and Hyperparameter Optimization}, CASH) acu√±ado por Auto-Weka \brackcite{thornton2013auto}. M\'as formalmente:
\begin{definition}
    Sea $A = \{a^1, ..., a^k\}$  un conjunto de algoritmos con espacios de configuraci\'on asociados $\Lambda^1, ..., \lambda^k$.
    Sea $D$ un conjunto de datos  que se divide en $\{D_{t}^{(1)},..., D_{t}^{(k)}\}$ y $\{D_{v}^{(1)},..., D_{v}^{(k)}\}$ 
    tal que $\forall i, 1 \leq i \leq k$ se cumple que $D_{t}^{(i)} = D \setminus D^{(i)}_{v}$
    El problema CASH se define como el computo de:
    \begin{equation*}
        a^*_{\lambda^*} \in argmin_{a^{(j)} \in A, \lambda \in \Lambda^{(j)}} \frac{1}{k} \sum^{k}_{i = 1}\mathcal{L}(a^(j)_\lambda, D^{(i)}_t, D^{(i)}_v)
    \end{equation*}
    Donde $\mathcal{L}(a, D_t, D_v)$ es la funci\'on de p\'erdida al ser entrenado en $D_t$ y evaluado en $D_v$.
\end{definition}


% El objetivo es transferir el problema de combinaci\'on, selcci\'on y optimizaci\'on de hiperpar\'ametros(\textit{Combined Algorithm Selection and Hyperparameter Optimization}, CASH por sus siglas en ingl\'es) del investigador al sistema, permitiendole a este enfocarse en otras tareas como la validaci\'on de los datos o ingenier\'ia de caracter\'isticas.

El campo del Aprendizaje de M\'aquina Automatizado cuenta con numerosas propuestas de distintos dominios: 
\begin{itemize}
    \item Optimizaci\'on Bayesiana%(\brackcite{hutter2019automated})
    \item Programaci\'on Evolutiva%(\brackcite{chen2018autostacker})
    \item B\'usqueda Aleatoria 
    \item Aprendizaje por Refuerzo
    \item M\'etodo de Gradiente
    \item Modelos Constructivos
    \item Monte Carlo
\end{itemize}

\subsection{Optimizaci\'on Bayesiana}
% TODO: Referencias a esta explicacion
Las propuestas basadas en optimizaci\'on bayesiana est\'an divididas en dos componentes principales: un modelo estad\'istico bayesiano para modelar la funci\'on objetivo, y una funci\'on de adquisici\'on que dirige la b\'usqueda en el espacio. Esos sistemas utilizan el modelo estad\'istico para seleccionar el mejor candidato a evaluar. Luego de la evaluaci\'on se actualiza el modelo y se repite el proceso.

\paragraph{Auto-WEKA \brackcite{thornton2013auto}} Utiliza como algoritmos de aprendizaje las m\'aquinas WEKA, una biblioteca de Aprendizaje Autom\'atico en Java. Presenta dos optimizadores bayesianos, una propuesta de configuraci\'on secuencial de Algortimos basados en Modelos \brackcite{hutter2011sequential}  y un estimador de Parzen con estrucutra de \'arbol \brackcite{bergstra2011algorithms}, ambos se ejecutan en paralelo y se retorna la funci\'on con menor error de validaci\'on de entre todas las descubiertas.

% TODO: Referenicar le meta-aprendizaje
% TODO: Gerundios?
\paragraph*{Auto-skelearn \brackcite{feurer2015efficient}} Utiliza como biblioteca de aprendizaje autom\'atico a scikit-learn (\brackcite{pedregosa2011scikit}) y extiende la propuesta de AutoWEKA  introduciendo mejoras como la inclusi\'on de un paso de meta-aprendizaje que reduce el espacio de b\'usqueda aprendiendo de modelos que obtuvieron un buen desempe\~no en conjuntos de datos similares y luego un paso de selecci\'on de ensemblers que le permite reusar los flujos de Aprendizaje de M\'aquina que tuvieron mejor rendimiento. 

% TODO: Gerundios y participios?
\paragraph*{HyperOpt-Sklearn \brackcite{komer2014hyperopt}} Similar a Auto-Skelearn con respecto a la biblioteca de aprendizaje subyacente, scikit-learn, utiliza Hyperopt \brackcite{bergstra2013hyperopt} para describir el espacio de b\'usqueda. Provee una interfaz de optimizaci\'on que distingue un espacio de configuraciones y una funci\'on de evaluaci\'on que asigna valores de p\'erdida reales a puntos dentro de dicho espacio. Hyperopt requiere que el espacio est\'e definido como una distribuci\'on de probabilidad, permitiendo una codificaci\'on m\'as expresiva de las intuiciones de los expertos con respecto a los valores de los hiperpar\'ametros. Utiliza SMBO (\textit{Sequential Model-based Bayesian Optimization}), considerando este algoritmo como una componente intercambiable con el fin de que cualquier t\'ecnica de b\'usqueda pueda ser utilizada con cualquier problema de b\'usqueda.

% TODO: brackcite keras, or autokeras
\paragraph*{Auto-Keras \brackcite{jin2018efficient}} Un sistema de AutoML enfocado en resolver el problema NAS. Est\'a basado en la biblioteca Keras de Python, utilizada para crear redes neuronales.  La idea principal de esta propuesta es explorar el espacio mediante la transformaci\'on de redes, utilizando un algoritmo de Optimizaci\'on Bayesiana eficiente. Dichas transformaciones permiten generar redes manteniendo las configuraciones alcanzadas con entrenamientos anteriores, disminuyendo el uso de los recursos de c\'omputo. Auto-Keras a nivel t\'ecnico est\'a estructurado para el uso eficiente de la memoria y la ejecuci\'on en paralelo sobre el CPU y el GPU.

% TODO: Quitar el anglicismo
\paragraph*{autogxgboost \brackcite{thomas2018automatic}} Se cataloga como un sistema AutoML \textit {single-learner} pues solo utiliza un algoritmo de aprendizaje y optimiza los hiperpar\'ametros para este utilizando optimizaci\'on bayesiana. Requiere que el algoritmo sea un m\'etodo de aumento de gradiente con \'arboles (\textit{Gradient Boosting with Trees}, GBT) como \textit {xgboost} \brackcite{chen2016xgboost} debido a su prometedor rendimiento con los par\'ametros adecuados.   
    
\subsection{Programaci\'on Evolutiva}
     Los sistemas AutoML basados en programaci\'on evolutiva crean una poblaci\'on inicial de flujos v\'alidos para luego seleccionar los de mejor rendimiento respecto a cierta m\'etrica. Los m\'as aptos son utilizados para crear la poblaci\'on de la pr\'oxima iteraci\'on. Las propuestas difieren principalmente en como modelan el espacio de b\'usqueda y qu\'e estrategias usan para crear los nuevos individuos.
     
\paragraph*{TPOT \brackcite{pmlr-v64-olson_tpot_2016}} Utiliza algoritmos de aprendizaje de la biblioteca scikit-learn \brackcite{pedregosa2011scikit} junto con el algoritmo xgboost \brackcite{chen2016xgboost}, es uno de los sistemas AutoML evolutivos m\'as reconocidos. Cada algoritmo de Aprendizaje Autom\'atico a su disposici\'on se le considera un operador, adem\'as de tener un operador especial de cruce. Permite tener varias copias del conjunto de datos y aplicar operadores sobre ellos simult\'aneamente para luego recombinarlos y crear flujos con los operadores que hayan tenido mejor rendimiento. TPOT adem\'as realiza una b\'usqueda multiobjetivo sobre las soluciones encontradas utilizando NSGA-II \brackcite{deb2002fast} que maximiza la relevancia de los resultados y minimiza la cantidad de operadores aplicados sobre los flujos de Aprendizaje Autom\'atico. % para mantener las soluciones simples y evitar el sobreajuste a los datos.

\paragraph*{RECIPE \brackcite{de2017recipe}} Utiliza programaci\'on gen\'etica basado en gram\'aticas (\textit{Grammar Genetic Programming}, GGP) para generar sus flujos. El sistema recibe como entrada un conjunto de datos y una gram\'atica libre del contexto (CFG) que utiliza para formar una poblaci\'on inicial de flujos. Partiendo de los mejores individuos aplica operadores de mutaci\'on y cruce sobre estos tal que no se violen las reglas de la gram\'atica para la obtenci\'on de una nueva poblaci\'on. Utiliza como base de aprendizaje a la bibliotea scikit-learn \brackcite{pedregosa2011scikit}.
 

\paragraph{AutoGOAL \brackcite{estevez2020solving}} Utiliza una Gram\'atica Probabil\'istca Libre del Contexto (\textit{Probabilistic Context-Free Grammars}) para modelar el espacio de b\'usqueda y Evoluci\'on de Gram\'atica  Probabil\'istica (\textit{Probabilistic Grammatic Evolution}) \brackcite{megane2021probabilistic} para dirigir la b\'usqueda de acuerdo a los individuos m\'as aptos de cada iteraci\'on. AutoGOAL est\'a compuesto por gran cantidad de algoritmos de aprendizaje de diversas bibliotecas de Python que le  permite abarcar problemas de cualquier tipo, incluido problemas de procesamiento de lenguaje natural, donde cuenta con algoritmos pre-procesadores de datos.

\subsection{B\'usqueda Aleatoria}
Los sistemas basados en B\'usqueda Aleatoria realizan en la exploraci\'on del espacio de b\'usqueda, ya sea de forma secuencial o en paralelo mediante la selecci\'on de soluciones aleatorias. Utiliza una red aleatoria inicial (o predeterminada) para genera nuevas redes las cuales son evaluadas. La red generada con mejor puntuaci\'on se coge como punto de partida para la siguiente iteraci\'on. Las propuestas var\'ian seg\'un como se generan y eval\'uan dichas redes. 
%Este m\'etodo se utiliza muchas veces como comparaci\'on frente a estrategias m\'as avanzadas.

        % TODO: Poner nash en espannol?
        \paragraph{NASH \brackcite{wei2016network}} Neural Arquitecture Search by Hillclimbing es una propuesta de soluci\'on al problema NAS.
Partiendo de una red aleatoria o predeterminada a la cual se le aplica \textit{morfismos de red} para obtener  nuevas redes ``vecinas''. Se eval\'uan de acuerdo a una  m\'etrica y la que tenga mejor rendimiento se toma como principal y se repite el proceso partiendo de esta. La estrategia de \textit{hill climbing} que sigue elimina la necesidad de reentrenar las nuevas redes desde cero.

        \paragraph{H20 AutoML \brackcite{ledell2020h2o}} Disponible en varios lenguajes de programaci\'on, utiliza los algoritmos de Aprendizaje Autom\'atico definidos en la biblioteca H20 \brackcite{boehmke2019hands}. Construye m\'ultiples modelos con diferentes juegos de hiperpar\'ametros seleccionados aleatoriamente en base a ciertas heur\'isticas. En funci\'on de la disponibilidad de recursos de c\'omputo, la b\'usqueda se detiene y los mejores modelos se utilizan para construir un ensemble.

        % TODO: Cuan grandes los datasets?
        \paragraph{TransmogrifAI \brackcite{tovbin93meet}}  Se dise\~na con el objetivo de tener un buen rendimiento en corpus de datos grandes. Encapsula cinco componentes del proceso de aprendizaje autom\'atico en diferentes pasos:
        \begin{enumerate}
            \item Realiza un preprocesamiento de los datos donde obliga al cient\'ifico a especificar un esquema y establecer un sistema de tipos sobre estos. Transmogrif los analiza siendo capaz de inferir el tipo de algunos.
            \item Aplica ingenier\'ia de caracter\'isticas automatizada: busca obtener la representaci\'on n\'umerica adecuada para cualquier tipo de datos.
            % TODO: Hablar de los problemas que eso acarrea?
            \item Hace una validaci\'on de las caracter\'isticas para mitigar la probable explosi\'on de dimensionalidad ocurrida en el paso anterior y los problemas que ello acarrea.
            \item Resuelve el problema de selecci\'on autom\'atica de modelos ejecutando un torneo de varios algoritmos de Aprendizaje Autom\'atico, y escoge el mejor seg\'un el error de validaci\'on promedio.
            \item En cada uno de los pasos anteriores se ejecuta adem\'as un paso subyacente de optimizaci\'on de hiperpar\'ametros, contrario a  muchos sistemas AutoML que optimizan solamente para el modelo soluci\'on. 
        \end{enumerate}
        %donde la b\'usqueda se realiza sobre el espacio de las transformaciones de caracter\'isticas que son posibles en funci\'on de los datos utilizados.


\subsection{Aprendizaje por Refuerzo}
El aprendizaje por refuerzo como estrategia de b\'usqueda consiste en entrenar un agente que realiza modificaciones sobre una soluci\'on con el objetivo de maximizar una recompensa que depende del rendimiento de dicha soluci\'on. Esta estrategia se utiliza mayormente en sistemas AutoML que buscan resolver el problema NAS, donde el agente puede realizar acciones como a\~nadir, remover, o modificar una capa o sus hiperpar\'ametros. Las propuestas difieren seg\'un el dise\~no del agente.

        % Para la representaci\'on de NAS como un problemam de aprendizaje por refuerzo, la generaci\'on de una rquitectura se considera como una acci\'on de un agente siendo el esapcio deacciones id\'entico al espacio de b\'usqueda. La recompenza del agente se basa en el rendimiento de las redes entrenadas. Las propuestas difieren en como se represente la politica del agente y como la optimizan.


        % TODO: Que es un metacontrolador
        \paragraph*{EAS \brackcite{cai2018efficient}} Efficient Arquitectural Search utiliza un meta-controlador basado en aprendizaje por refuerzo  (\textit{Reinforcment Learning}, RL) \brackcite{kaelbling1996reinforcement} y el algoritmo REINFORCE \brackcite{williams1992simple} para actualizarlo. En general, este sistema modela el proceso de dise\~no autom\'atico de arquitecutras como un proceso de toma de decisiones secuencial, donde verifica el estado de la red actual y realiza la operaci\'on de transformaci\'on correspondiente. Despu\'es de una cantidad determinada de pasos, la arquitectura resultante se eval\'ua para obtener la se\~nal de recompensa, que luego se utiliza para actualizar el meta-controlador, maximizando la validaci\'on.

        \paragraph*{NASNet \brackcite{zoph2018learning}} Utiliza aprendizaje por refuerzo para la construcci\'on \'optima de una red neural para cualquier conjunto de im\'agenes. La contribuci\'on clave de esta propuesta es que el dise√±o del espacio de b\'usqueda permite construir la arquitectura en un corpus de datos peque\~no y luego transferir los conocimientos para el entrenamiento de un conjunto de datos m\'as grande, aligerando el costo computacional de aplicarlo directamente sobre un corpus grande.


% \section{M\'etodos de Gradiente}
% Los m\'etodos que utilizan esta estraetigan buscan calcular la direcci\'on del gradiente tal que se mejore el rendimiento de la soluci\'on inicial y evaluar nuevas soluciones en la vecindad de dicha direcci\'on. Cuando se tiene un espacio de b\'usqueda diferenciable el gradiente se puede calcular de forma exacta.

    % \paragraph*{DARTS} eso

\subsection{Modelos Constructivos}
% Gerundios y participios
Estos m\'etodos exploran el espacio de b\'usqueda con una forma estructurada pues se define de antemano los posibles modelos y formas de combinarlos. Se establece un orden de evaluaci\'on de las soluciones y la b\'usqueda finaliza cuando todo el espacio ha sido explorado. Esta estrategia es \'util cuando el espacio de b\'usqueda es peque\~no y consta de modelos bien definidos, variados y con un buen rendimiento.

\paragraph{AutoGluon \brackcite{erickson2020autogluon}} Realiza procesamiento de datos avanzados, aprendizaje profundo y ensamblaje de modelos multicapa. Reconoce autom\'aticamente el tipo de datos de cada columna para un procesamiento de datos robustos, luego construye un ensemble multicapa  que toma como entrada la instancia de cada uno de los tipos de modelos predefinidos. Cada modelo se entrena de forma secuencial y se a\~nade al ensemble. Para finalizar, se realiza un proceso de post-optimizaci\'on para destilar el ensemble resultante en un modelo m\'as peque\~no con rendimiento similar.

\subsection{Monte Carlo}
 Esta estrategia se emplea en espacios de b\'usquedas jer\'arquicos para explorar eficientemente el \'arbol que describe todas las  posibles soluciones. En cada iteraci\'on se deciende por una rama del \'arbol hasta llegar a un nodo hoja, el camino representa una posible soluci\'on. Como todo algoritmo de Monte Carlo, requiere de una definici\'on adecuada de una funci\'on que permita un balance entre exploraci\'on y explotaci\'on. Esta estrategia require un espacio de b\'usqueda donde las decisiones m\'as importantes est\'en posicionadas al principio en el \'arbol para ser efectiva.

 \paragraph{ML-Plan \brackcite{mohr2018ml}} Un sistema basado en redes de tareas jer\'arquicas (HTN) \brackcite{erol1994umcp}. La b\'usqueda es aleatoria, construyendo flujos parciales junto con un mecanismo que evita el sobreajuste. Cuenta con con dos tipos de algoritmos:  preprocesadores de datos y de aprendizaje. Sus flujos son un par compuesto por un procesador parametrizado y un algoritmo de aprendizaje.
    


\section{Optimizaci\'on Multiobjetivo}\label{background:moo}
Optimizaci\'on Multiobjetivo es la rama de la Ciencia y la Matem\'atica que se dedica a optimizar varias funciones objetivos simult\'aneamente.
Aplicada principalmente en las ingenier\'ias y la econom\'ia donde  suelen existir conflictos entre los objetivos a optimizar.
Ejemplo de su aplicaci\'on son: %Su aplicaci\'on es amplia y variada: 
%Exsiten muchos aplicaciones en la actualidad que se benefician de aplicar optimizaci\'on multiobjetivo, por ejemplo:
\begin{itemize}
    \item La necesidad de lograr un balance entre energ\'ia producida y combustible utilizado por una termoel\'ectrica \brackcite{shirazi2012thermal}\brackcite{shirazi2014thermal}.
    \item El dise\~no \'optimo de una estructura como la configuraci\'on de gabinete de control \brackcite{pllana2019customizing} o una granja solar \brackcite{ganesan2013hypervolume}.
    \item La inspecci\'on de infraestructura complejas, que es muy costosa y no resulta factible cubrir el \'area completa por lo que hay que buscar una soluci\'on \'optima que haga concesiones entre \'area cubierta y costos \brackcite{ellefsen2017multiobjective}.
    \item La distribuci\'on adecuada de recursos de radio para satisfacer eficientemente el requerimiento de sus usuarios \brackcite{bjornson2013optimal}.
\end{itemize}

El problema multiobjetivo consiste en optimizar varias funciones y lograr soluciones que hagan concesiones pertinentes entre los criterios que tengan conflictos entre s\'i.
\begin{definition}{Optimizaci\'on Multiobjetivo:}
    \label{background:def:moo}
     Dado $m$ funciones objetivos: $f_1: \mathcal{X} \rightarrow \mathbb{R}, ..., f_m: \mathcal{X} \rightarrow \mathbb{R}$ que transforman un vector $x$ del espacio de decisi\'on $\mathcal{X}$ a un valor de $\mathbb{R}$. Se define el problema multiobjetivo como:
    \begin{equation*}
        \min f_1(x), ..., f_m(x), x \in \mathcal{X}
    \end{equation*}
\end{definition}

% Annadir  xq conno se llama Frente de Pareto
Cuando se optimizan varias funciones, la mejor soluci\'on  no es un escalar, sino un vector y no necesariamente \'unico pues al haber m\'as de dos medidas de evaluaci\'on un vector puede ser superior a otro con respecto a ciertas componentes pero no en todas. Un vector se dice mejor o que \textit{Pareto domina} a otro cuando es superior en al menos una componente y no peor en las restantes. Se conoce formalmente en la literatura como \textit{Pareto dominaci\'on}.
\begin{definition}{Pareto Dominaci\'on:}
    \label{background:def:domintation}
    Dado dos vectores en el el espacio objetivo, $x, z \in \mathcal{Y}$, se dice que $x$ Pareto domina a $z$ (i.e. $x \prec z$), si y solo si:
    \begin{equation*}
        \forall i \in \{1, ..., m\}: x_i \leq z_i \text{ y } \exists j \in \{1, ..., m\}: x_j < z_j
    \end{equation*}
\end{definition}

Cuando se tiene un subconjunto de vectores, dentro de todo el espacio,  a los que ning\'un otro vector domina, se le  llama Frente de Pareto y es el conjunto soluci\'on del problema multiobjetivo.

\begin{definition}
    \label{background:def:pareto_front}
    \textit{Frente de Pareto}: Todos los vectores $x$ del espacio objetivo $\mathcal{Y}$ tal que no exista un vector $y \in \mathcal{Y}$ que \textit{Pareto domine} a $x$.
    \begin{align*}
        \mathcal{P} = \{x| x, y \in \mathcal{Y}, \neg \exists y \prec x \} 
    \end{align*}
\end{definition}

%TODO:
%Hablar sobre a priori, interactivo y a posteriori en la optimizacion multi objetivo?


El problema multiobjetivo se ha intentado resolver utilizando tres enfoques de diferentes campos de la Computaci\'on y la Matem\'atica:
\begin{enumerate}
    \item T\'ecnicas de Escalarizaci\'on.
    \item M\'etodos Num\'ericos.
    \item Algoritmos Evolutivos.
\end{enumerate}


% A√±adir problemas que se hayan resulto con multiobjetivo
% El objetvio es mostrar lo mucho que se ha usado multiobjetivo 
% Y lo poco que se ha utilizado en automl
% Decir que lo vamos a probar 

\subsection{T\'ecnicas de Escalarizaci\'on }

Las t\'ecnicas de escalarizaci\'on han sido las m\'as utilizadas para resolver el problema multiobjetivo \brackcite{miettinen2012nonlinear}. Estas t\'ecnicas consisten en agregar funciones objetivos o  reformularlas como restricciones en una sola funci\'on sobre la cual se aplica un m\'etodo de optimizaci\'on est\'andar de un solo objetivo. La nueva funci\'on objetivo adem\'as se parametriza con un vector de pesos, que dependiendo de sus valores resulta en un punto distinto del frente de Pareto. Seg\'un como se confome la funci\'on objetivo se definen los m\'etodos de escalarizaci\'on:
\begin{enumerate}
    \item Linear Weighting: Se combinan todas las funciones objetivos en una suma. A cada funci\'on objetivo se le asigna un escalar de peso.
    \begin{equation*}
        \min \sum w_i f_i(x), \space x \in X
    \end{equation*}
    Se garantiza que una soluci\'on de esta nueva funci\'on objetivo siempre est\'a sobre el frente de Pareto  y si este es convexo se puede hallar cualquier punto de este con el correcto vector de peso \brackcite{emmerich2018tutorial}. El problema yace cuando el frente de Pareto tiene forma c\'oncava donde \textit{Linear Weighting} resulta insuficiente por no ser capaz obtener los puntos de esta secci\'on del frente.

    \item $\epsilon$-constrain: Se selecciona una funci\'on objetivo como principal y las dem\'as se establecen como restricciones al conjunto de soluciones factibles exigiendo que sean menor que cierto $\epsilon_i$  por cada funci\'on objetivo.
    \begin{align*}
            \min  f_1(x), \space x \in X  & \text{, sujeto a:}   \\
            g_i(x) \leq \epsilon_i & \quad  \forall i, 2 \leq i \leq n
    \end{align*}
    Este enfoque presenta dos dificultades principales: la valores de los $\epsilon_i$, para una adecuada selecci\'on, requiren conocimiento previo del frente de Pareto y, al igual que \textit{Linear Weighting}, no es capaz de detectar soluciones en las partes c\'oncavas del frente \brackcite{emmerich2018tutorial}.

    % TODO: Que condicion cumple los pesos de Chebychev
\item Chebychev Distance (CSP): Se establece un punto de referencia $z^*$ y se utiliza la distancia de Chebychev de los vectores objetivos hacia este como funci\'on objetivo utilizando un vector de pesos $\lambda \in \mathbb{R}^m_{\prec 0}$, donde $\mathbb{R}^m_{\prec 0} = \{x | x \in \mathbb{R}^m, x \prec 0 \}$. 
    \begin{align*}
        \min \quad \max_{i \in {1,...,m}} \lambda_i |f_i(x) - z^*_i|, x \in X 
    \end{align*}
    CSP dado un punto de referencia y vector de pesos adecuados puede encontrar cualquier punto del frente de Pareto, no importa su forma \brackcite{emmerich2018tutorial}.
\end{enumerate}

% Improve this paragraph, merge it on top
% Recientemente escalarizaci\'on ha encontrado uso en algoritmos gen\'eticos por descomposici\'on para obtener muestras distintas del frente de Pareto.  En \cite{paria2020flexible} se propone un algoritmo capaz de muestrear un \'area determinada del frente de Pareto a partir de una estrategia basada en escalarizaci\'on aleatoria.


\subsection{Algoritmos Num\'ericos}

% TODO: Es esto verdad?
En principio todos los algoritmos de escalarizaci\'on se pueden resolver utilizando m\'etodos num\'ericos. Adem\'as existen otros m\'etodos  que intentan resolver el problema haciendo cumplir las condiciones de Karush-Kuhn-Tucker (KKT) \brackcite{kuhn2014nonlinear}.

La idea va de encontrar al menos una soluci\'on al sistema de ecuaciones creado tras intentar resolver el problema KKT. Luego se utilizan m\'etodos de continuaci\'on y homotop\'ia para a√±adir al conjunto soluci\'on soluciones cercanas a esta. 
Este tipo de enfoque no es ideal para espacios de b\'usqueda complejos pues requiere que las soluciones satisfagan las condiciones de convexidad local y diferenciabilidad \brackcite{hillermeier2001nonlinear}\brackcite{schutze_et_al:DagSemProc.04461.16}.

Existen otros m\'etodos para la b\'usqueda de m\'inimos globales como \textit{T\'ecnicas de Subdivisi\'on} por \brackcite{dellnitz2005covering}, \textit{Optimizaci\'on Global Bayesiana} \brackcite{emmerich2016multicriteria} y \textit{Optimizaci\'on de Lipschitz} \brackcite{vzilinskas2013worst}. % Estas requiren de que el espacio de decisi\'on tenga una baja dimensionalidad.
as\'i como m\'etodos que no necesiten diferenciar para su resoluci\'on utilizando t\'ecnicas de b\'usquedas directas \brackcite{custodio2011direct}\brackcite{audet2010mesh}.

\subsection{Algoritmos Evolutivos Multiobjetivos }

Los algoritmos gen\'eticos utilizan paradigmas extra\'idos de la naturaleza, tal como selecci\'on natural, mutaci\'on y recombinaci\'on para dirigir una poblaci\'on (o conjunto de vectores de decisi\'on) hacia una soluci\'on \'optima \brackcite{back1996evolutionary}.

Los algoritmos evolutivos multiobjetivos (MOEA por sus siglas en ingl\'es) generalizan esta idea, y son dise√±ados para acercarse en cada iteraci\'on  al frente de Pareto. Como en este caso no existe soluci\'on \'unica, la manera de seleccionar los individuos cambia fundamentalmente. Dentro de los MOEA existen tres paradigmas principales:

\begin{enumerate}
    \item \textbf{MOEA basados en el frente de Pareto}\label{background:def:MOEA}: Se identifican por dividir el proceso de selecci\'on en dos etapas. En la primera se organizan los individuos seg\'un su \'indice de dominaci\'on y se acomodan en distintos subconjuntos seg\'un la cantidad de soluciones que los dominen (e.g. un subconjunto para las soluciones a las cuales nadie domina, otro para los son dominados por alguna soluci\'on etc.). En la segunda ordenaci\'on cada subconjunto se ordena buscando que los primeros lugares sean los elementos m\'as representativos de cada subconjunto. NSGA-II \brackcite{deb2002fast} y SPEA2 \brackcite{zitzler1999multiobjective} son algoritmos de este tipo.

    \item \textbf{Basados en indicador}: Estos utilizan un indicador para calcular cuan cercano es el conjunto actual al frente de Pareto (unario), o cuanto mejora el nuevo conjunto de soluciones respecto a la iteraci\'on anterior (binario). Ejemplo de este es SMS-EMOEA \brackcite{emmerich2005emo} que suele converger al frente de Pareto con soluciones igualmente distribuidas.

    \item \textbf{Basados en descomposici\'on}: La idea principal consiste en descomponer el problema en peque√±os subproblemas cada una correspondiente a una secci\'on del frente de Pareto. Cada subproblema se resuelve utilizando escalarizaci\'on con diferente parametrizaci\'on. 
       % El m\'etodo de escalarizaci\'on m\'as usado en estos casos suele ser CSP debido a ser capaz de obtener cualquier punto del frente de Pareto.
        Ejemplo de este paradigma son MOEA/D \brackcite{zhang2007moea}, NSGA-III \brackcite{deb2013evolutionary} y MOMSA \brackcite{sharifi2021new}.

\end{enumerate}

% TODO: (Poner esto en alg\'un lado)
 El t\'ermino Optimizaci\'on Multiobjetivo se utiliza cuando el n\'umero de funciones objetivos son dos o tres. Para un cantidad de criterios mayor se le conoce coloquialmente en la literatura como Optimizaci\'on para Muchos Objetivos o \textit{many-objective optimization} en ingl\'es, propuesto inicialmente por \brackcite{10.1007/978-3-540-31880-4_2}. Se hace \'enfasis en esta diferenciaci\'on pues al aumentar el n\'umero de m\'etricas a optimizar:
 \begin{enumerate}
     \item No es posible visualizar el frente de Pareto.
     \item La computaci\'on de indicadores o de selecci\'on para muchos algoritmos se convierte en problemas NP-duros.
     \item Existe un r\'apido crecimiento de puntos no dominados, mientras mayor n\'umero de objetivos, la probabilidad de que un punto sea no dominado en un set con distribuci\'on normal tiende exponencialmente a 1.
 \end{enumerate}

% TODO: Referenciar esto
Los algoritmos que mejor han tenido resultado en esta \'area son los algoritmos basados en descomposici\'on.


\section{AutoML y Multiobjetivo}\label{background:mooautoml}
% En el campo del aprendizaje de m\'aqina han habido varias investigaciones respecto a la Optimizaci\'on Multibobjetivo.  An\'alisis de curva caracter\'istca de receptor (\textit{receiver operating characteristic curve}, ROC) de \brackcite{everson2006multi} para calcular el costo de clasificaciones err\'oneas de un clasificador mostrando gr\'aficamente un intercambio entre los verdaderos y falsos positvos de dos o m\'as problemas de clasificaci\'on utilizando Optimizaci\'on Multiobjetivo. 
% \brackcite{jin2008pareto} hacen un analisis sobre la adici\'on de optimizaci\'on multibojetivo al Aprendizaje de M\'aquina. Compara los diferentes enfoques de escalarizaci\'on y algoritmos gen\'eticos.
% En el campo de configuraci\'on de algoritmos \brackcite{blot2016mo} introduce un busqueda iterativa local basado en multiples criterios para configurar solucionadores SAT.

La comunidad FatML (\textit{Fairness, Accountability and Transparency in Machine Learning}) hace \'enfasis sobre como optimizar para una sola m\'etrica acarrea problemas que pueden ser evitados optimizando simult\'aneamente para m\'ultiples criterios \brackcite{barocas2017fairness}. No obstante, es escaso el estudio sobre sistemas de Aprendizaje de M\'aquina Automatizado a los que se les aplica optimizaci\'on multiobjetivo.

Se define el problema multiobjetivo aplicado a sistemas AutoML de la siguiente manera:
\begin{definition}\label{background:def:moo-automl-problem}
    Dado un conjuntos de datos $D$ y  un conjunto de m\'etricas a evaluar $M = \{f_1, f_2, ...,f_m\}$, se espera que  un sistema AutoML $\mathcal{A}$ retorne un conjunto de flujos, algoritmos o redes $P = \{p_1, p_2, ..., p_k\}$ tal que su evaluaci\'on con respecto a las m\'etricas en $M$ sean una aproximaci\'on del frente de Pareto en el espacio objetivo $\mathcal{Y}$ .
    \begin{equation*}
        \mathcal{A}(D, M) = P  
    \end{equation*}
\end{definition}

TPOT \brackcite{pmlr-v64-olson_tpot_2016} es un ejemplo de Sistema AutoML que aplica multiobjetivo para su resoluci\'on. Despu\'es de cada iteraci\'on ordena los algoritmos utilizando NSGA-II \brackcite{deb2002fast} gui\'andose por exactitud de las predicciones y n\'umero de operadores utilizados (i.e. algoritmos de aprendizaje). No obstante el resultado de TPOT no es un conjunto soluciones representativas del frente de Pareto, sino la soluci\'on que mejor rendimiento tuvo respecto a una m\'etrica de relevancia durante las pruebas de validaci\'on. El uso de optimizaci\'on multiobjetivo en TPOT se utiliza principalmente como medida para evitar el sobre ajuste del modelo a los datos.

\textit {Multi-Objective AutoxgboostMC}\brackcite{pfisterer2019multi} propone una soluci\'on al problema multiobjetivo. Se basa en la t\'ecnica de aprendizaje \textit{autoxgboost} \brackcite{thomas2018automatic} y utiliza  parEgo \brackcite{knowles2006parego}, un sistema de escalarizaci\'on multiobjetivo utilizando CSP. La funci\'on restultante tras aplicar CSP sobre las m\'utiples m\'etricas  es optimizada utilizando optimizaci\'on bayesiana est\'andar de un s\'olo objetivo.
El algoritmo se beneficia de un humano en el proceso de optimizaci\'on que ayuda a guiar la b\'usqueda aplicando restricciones sobre el espacio de b\'usqueda interactivamente.
Al estar basado en \textit{autoxgboost} \brackcite{thomas2018automatic} un sistema AutoML que utiliza un solo algoritmo, el espacio de b\'usqueda se encuentra limitado y es posible que no incluya configuraciones \'optimas.

% El estudio de optimizaci\'on en sistemas Aprendizaje de M\'aqina Automatizado es bastante escaso. Entre los sistemas AutoML que cuentan con esta caracter\'istica se encuentra es TPOT \brackcite{pmlr-v64-olson_tpot_2016} que optimiza mutuamente para exactitud y modelos de Aprendizaje de Maquina m\'as sencillos, no obstante estas m\'etricas est\'an fijas y el progrmador no puede modificarlas, ni a\~nadir m\'as.
% En \brackcite{pfisterer2019multi} se propone una adici\'on a \textit{autoxgboost} (\cite{thomas2018automatic}) para optimizar multiobjetivo utilizando un algoritmo de simple de escalarizaci\'on. Esta implementaci\'on es flexible en cuanto a m\'etricas utilizar.

% En AutoGOAL se propone la adici\'on de optimizar para varios objetivos utilizando un algoritmo gen\'etico que est\'an demostrados que son resistentes a la forma del frente de Pareto. Los objetivos seri\'ian definidos por el usuario y la respuesta ser\'ia un conjunto de flujos de ML que estuvieran en el frente de Pareto.


