\chapter{Estado del Arte}\label{chapter:state-of-the-art}
El proceso de investigaci\'on para formar un modelo de aprendizaje de m\'aquina requiere varia experemintaci\'on donde se utilizan y combinan d\'sieles t\'ecnicas como redes neuronales, clasificadores supervistados, algoritmos de agrupamientos, etc.). Adem\'as hay que escoger par\'ameros un proceso que se gu\'iado por prueba y error. 

Un algorimto de aprendizje de m\'aquina automatizado es un campo cada vez m\'as creciente cuyo objetivo es encontrar flujos de aprendizajes autom\'aticos \'optimos en variados escenarios. La comunidad de AutoML se ha centrado en producir sistemas de AutoML con espacios de b\'usqeudas cada vez m\'as complejos y mejoras en la selecci\'on de hiperparametros con tal de encontrar el modelo \'optimo.

Cuando esta parte proceso de las manos se quita del investigador, este puede utilizar ese tiempo para enfocarse en otros asuntos, pero tambi\'en pierde un poco. Si para el investigador que el sistema produzca resultados relevantes no es suficiente el sistema AutoML se vuelve inutil que que si se desea un flujo o algoritmo que tenga buenos resultados en una m\'etrica adicional.

En la secci\'on \ref{proposal:automl} se  hace un estudio del estado del arte en AutoML. Luego en la secci\'on \ref{proposal:moo} se estudia los diferentes paradigmas de Optimizaci\'on Multiobjetivo y se muestran diferentes propuestas de cada uno. Finalmente en la secci\'on \ref{proposal:mooautoml} se analiza casos conocidos donde al problema AutoML se le ha aplicado optimizaci\'on multiobjetivo.

\section{Aprendizaje de M\'aquina Automatizado}\label{proposal:automl}
% Que es AutoML
El Aprendizaje de M\'aquina Automatizado (Automated Machine Learning, AutoML) consiste en la generaci\'on autom\'atica de flujos, algoritmos o par\'amteros que resuelven un problema determinado minimizando la dependencia del usuario. 

Actualmente los sistemas AutoML se pueden en separar en dos conjuntos dependiendo del problema a resolver. Se encuentran los sistemas orientados a aprendizaje profundo conocido como B\'usqueda de Arquitecturas Neuronales (\textit{Neural Arquitectural Search}, NAS) y  Auto-ML basado en selecci\'on y combinaci\'on de modelos que pueden resolver el problema NAS o no. El segundo conjunto intenta resolver el problema de combinaci\'on, selecci\'on y optimizaci\'on de hiperpar\'ametros (\textit{Combined Algorith Selection and Hyperparameter Optimization}, CASH) acu√±ado por Auto-Weka (\cite{thornton2013auto}). M\'as formalmente:


\begin{definition}
    Sea $A = \{a^1, ..., a^k\}$  un conjunto de algoritmos con espacios de configuraci\'on asociados $\Lambda^1, ..., \lambda^k$.
    Sea $D$ un conjunto de datos  que se divide en $\{D_{t}^{(1)},..., D_{t}^{(k)}\}$ y $\{D_{v}^{(1)},..., D_{v}^{(k)}\}$ 
    tal que $\forall i, 1 \leq i \leq k$ se cumple que $D_{t}^{(i)} = D \setminus D^{(i)}_{v}$
    El problema CASH se define como el computo de:
    \begin{equation*}
        a^*_{\lambda^*} \in argmin_{a^{(j)} \in A, \lambda \in \Lambda^{(j)}} \frac{1}{k} \sum^{k}_{i = 1}\mathcal{L}(a^(j)_\lambda, D^{(i)}_t, D^{(i)}_v)
    \end{equation*}
    Donde $\mathcal{L}(a, D_t, D_v)$ es la funci\'on de p\'erdida al ser entrenado en $D_t$ y evaluado en $D_v$.
\end{definition}


% El objetivo es transferir el problema de combinaci\'on, selcci\'on y optimizaci\'on de hiperpar\'ametros(\textit{Combined Algorithm Selection and Hyperparameter Optimization}, CASH por sus siglas en ingl\'es) del investigador al sistema, permitiendole a este enfocarse en otras tareas como la validaci\'on de los datos o ingenier\'ia de caracter\'istcas.

Existen variadas propuestas en el campo Aprendizaje de M\'aquina Automatizado, utilizando t\'ecnicas de diferentes dominios:
\begin{itemize}
    \item Optimizaci\'on Bayesiana(\cite{hutter2019automated})
    \item Programaci\'on Evolutiva (\cite{chen2018autostacker})
    \item B\'usqueda Aleatoria 
    \item Aprendizaje por Refuerzo
    \item M\'etodo de Gradiente
    \item Modelos Constructivos
    \item Monte Carlo
\end{itemize}

\subsection{Optimizaci\'on Bayesiana}
Las propuestas basadas en optimizaci\'on bayesiana est\'an divididas en dos componentes principales: un modelo estad\'istico bayesiano para modelar la funci\'on objetivo, y una funci\'on de adquisici\'on que dirige la b\'usqueda en el espacio. Esos sistemas utilizan el modelo estad\'istico para seleccionar el mejor candidato a evaluar. Luego de la evaluaci\'on se actualiza el modelo y se itera la b\'usqueda.

\paragraph{Auto-WEKA (\cite{thornton2013auto})} Presenta dos optimizadores bayesianos, una propuesta de configuraci\'on secuencia de Algortimos basados en Modelos (SMAC por \cite{hutter2011sequential}) y un estimador de Parzen con estrucutra de arbol (TPE por \cite{bergstra2011algorithms}), ambos se utilizan en paralelo y se retorna la funci\'on con menor error en validaci\'on de entre todas las descubiertas.

\paragraph*{Auto-skelearn (\cite{feurer2015efficient})} Utiliza como biblioteca de aprendizaje autom\'atico a scikit-learn (\cite{pedregosa2011scikit}) y extiende la propuesta de AutoWEKA  introduciendo mejoras com la inclusi\'on de un paso de meta-aprendizaje que reduce el espacio de b\'usquda aprendiendo de modelos que funcionaron bien en conjuntos de datos similares y luego un paso de selecci\'on de ensemblers que le permite reusar los flujos de Aprendizaje de M\'aquina que tuvieron mejor rendimiento. 

\paragraph*{HyperOpt-Sklearn (\cite{komer2014hyperopt})} Similar a Auto-Skelearn con respecto a la bibliteca de aprendizaje subyacente, scikit-learn, utiliza Hyperopt (\cite{bergstra2013hyperopt}) para describir el espacio de b\'usqueda. Provee una infterfaz de optimziaci\'on que distingue un espacio de configuraciones y una funci\'on de evaluaci\'on que asigna valores de perdida reales a puntos dentro de dicho espacio. Hyperopt requiere que el espacio est\'e definido como una distribuci\'on de probabilidad, permitiendo una codficacio\'on m\'as expresiva de las intuiciones de los expertos con respecto a los valores de los hiperpar\'ametros. Utiliza SMBO (Sequential Model-based Bayesian Optimization), consideraando este algoritmo como una componente intercambiable con el fin de que cualquier t\'ecninca de b\'usqueda pueda ser utilizada con cualquier problema de b\'usqueda.

      \paragraph*{Auto-Keras (\cite{jin2018efficient})} Un sistema de Auto-ML enfocado en resolver el problema NAS. Est\'a basado en la biblioteca Keras de Python, utilizada para crear redes neuronales.  La idea prinicipal de esta propuesta es explorar el espacio mediante la transformaci\'on de redes, utilizando un algorimto de Optmizaci\'on Bayesiana eficiente. Dichas transformaciones permiten generar redes manteniendo las configuraciones alcanzadas con entrenamientos anteriores, disminuyendo el uso de los recursod e c\'omputo. Auto-Keras a nivel t\'ecnico est\'a estructurado para el uso eficiente de la memoria y la ejecuci\'on en paralelo sobre el CPU y el GPU.

      \paragraph*{autogxgboost (\cite{thomas2018automatic})} Se cataloga asi mismo como un sistema AutoML \textit {single-learner} debido a que solo utiliza un algoritmo de aprendizaje y solamente optimzia los hiperpar\'ametros para este utilizando optimizaci\'on bayesiana. Requiere que el algoritmo sea un metodo de aumento de gradiente con \'arboles (\textit{Gradient Boosting with Trees}, GBT) como \textit {xgboost} (\cite{chen2016xgboost}) debido a su prometedor rendimiento con los param\'etros adecuados.   
    
\subsection{Programaci\'on Evolutiva}
     Bas\'andos en algoritmos gen\'eticos funcionan creando una poblaci\'on inicial de flujos v\'alidos, se seleccionan los de mejor rendmiento respecto a cierta m\'etrica y se utilzan para crear la poblaci\'on de la pr\'oxima iteraci\'on. Las propuestas difieren principalmente en como modelan el espacio de b\'usqueda y como se producen los nuevos individuos.
     \paragraph*{TPOT (\cite{pmlr-v64-olson_tpot_2016})} Basado en la biblioteca de aprendijaze autom\'atico scikit-learn (\cite{pedregosa2011scikit}) y el algoritmo xgboost (\cite{chen2016xgboost}), es uno de los sistemas AutoML evolutivos m\'as reconocidos en esta \'area. Cada algoritmo a su disposici\'on se considera un operador, adem\'as de tener un operador especial de cruce. Permite tener varias copias del dataset y aplicar operadores sobre ellos simult\'aneamente para luego recombinarlos y crear flujos con los operadores que hayan tenido mejor rendimiento. TPOT adem\'as realiza una b\'usqueda multiobjetivo sobre las soluciones encontradas utilizando NSGA-II (\cite{deb2002fast}) optimzando maximizar exactitud (\textit{accuracy} en la literatura) y minimizando la cantidad de operadores aplicados sobre los flujos de ML por un tema de simplicidad y evitar el sobreajuste a los datos.

     \paragraph*{RECIPE (\cite{de2017recipe})} Utiliza programaci\'on gen\'etica basado en gram\'aticas (\textit{Grammar Genetic Programming}, GGP) para generar sus flujos. El sistema recibe como entrada un conjunto de datos y una gram\'atica libre del contexto (CFG), que utiliza para formar una poblac\'on inicial de flujos. Define operadores de mutaci\'on y cruzamiento que fuerzan que se cumplan las reglas de producci\'on al aplicarse sobre un flujo. Utiliza coomo base la bibliotea Scikit-Learn

        % HML-Opt Precursor de AutoGOAL? Necesario ponerlo

     \paragraph{AutoGOAL (\cite{estevez2020solving})} genera soluciones utilizando una Grama\'atica Probabl\'istca Libre del Contexto para modelar el espacio de decisi\'on y Probabilistic Grammatic Evolution, un algortimos gen\'etico basados en EDA para construir las modelos de flujo. Tiene varios algorimtos bajo integrados y su generalidad permite abarcar problemas de cualquier tipo, incluido problemas de procesamiento de lenguage natura donde el sistema se encarga de pre-procesar los datos.


\subsection{B\'usqueda Aleatoria}
Consiste en la exploraci\'on del espacio de b\'usqueda, ya sea de forma secuencial o en paralelo mediante la selecci\'on de soluciones aleatorias. Este m\'etodo es utilizado muchas veces como comparaci\'on frente a estrategias m\'as avanazadas.

\paragraph{NASH (\cite{wei2016network})} Neural Arquitecture Search by Hillclimbing es una propuesta de soluci\'on al problema NAS.
        Partiendo de una red aleatoria o predeterminada le aplica morfismos de red para obtener  nuevas redes ``vecinas''. Se eval\'uan utilizando una funci\'on de evaluaci\'on y la que tenga mejor rendimiento se toma como principal y se reptie el proceso. La estrategia de hill climbing que sigue elimina la necesidad de rentrenar desde cero.

        \paragraph{H20 AutoML (\cite{ledell2020h2o})} Disponible en varios lenguages, utiliza la biblioteca H20 (\cite{boehmke2019hands}), una biblioteca de aprendizaje autom\'atico. Consturye multiples modelos con diferentes juegos de hiperpar\'ametros seleccionados aleatoriamente en base de ciertas heur\'isticas. En funci\'on de la disponibilidad de recursos de c\'omputo la b\'usqueda se detiene y los mejores modelos se utilizaan para construir un ensemble.

        \paragraph{TransmogrifAI (\cite{tovbin93meet})}  Dise√±ado para tener un buen rendimiento, fue dise\~nado para ejecutarse sober Apache Spark. Encapsula cinco componentes del proceso de aprendizaje autom\'atico en diferents pasos:
        \begin{enumerate}
            \item Se preprocesan los datos donde obliga al cient\'ifico especificar un esquema para estos y establecer un sistema de tipos sobre estos. Transmogrif los analiza siendo capaz de inferir el tipo de algunos.
            \item Aplica ingenieria de caracateristicas automatizada: eventualmente los datos sean del tipo que sean deben tener representaci\'on n\'umerica adecuada (todo una ciencia) y este sistema lo realiza por ti.
            \item Realiza una validaci\'on de las caracter\'isticas para mitigar  la probable explosi\'on de dimensionalidad ocurrida en el paso anterior y los problemas que acarrea.
            \item Resuelve el problema de selecci\'on autom\'atica de modelos ejecutanndo un torneo de varios algoritmos de aprendizaje de m\'aquina diferents, y escoge el mejor seg\'un el error de validaci\'on promedio.
            \item En cada paso de los anteriores se ejecuta adem\'as un paso de optimizci\'on de hiperpar\'ametros, contrario a lo que muchos sistemas AutoML que solo optimizan para el modelo. 
        \end{enumerate}
        %donde la b\'usqueda se realiza sobre el espacio de las transformaciones de caracter\'isticas que son posibles en funci\'on de los datos utilizados.


\subsection{Aprendizaje por Refuerzo}
El aprendizaje por refuerzo, como estrategia de b\'usqueda consiste en entrenar un agente que realiza modificaciones sobre una soluci\'on con el objetivo de maximizar una recompensa que depende del rendimiento de dicha soluci\'on. Est\'a estrategia es utilizada mayormente en sistemas AutoML que buscan resolver el problema NAS, donde el agente puede realizar acciones como a\~nadir, remover, o modificar una capa o sus hiperpar\'ametros. Las propuestas difieren seg\'un el dise\~no del agente.

        % Para la representaci\'on de NAS como un problemam de aprendizaje por refuerzo, la generaci\'on de una rquitectura se considera como una acci\'on de un agente siendo el esapcio deacciones id\'entico al espacio de b\'usqueda. La recompenza del agente se basa en el rendimiento de las redes entrenadas. Las propuestas difieren en como se represente la politica del agente y como la optimizan.

\paragraph*{EAS (\cite{cai2018efficient})} Effiecient Arquitectural Search es utiliza un meta-controlador basado en aprendizaje por refuerzo (\textit{Reinforcment Learning}, RL, \cite{kaelbling1996reinforcement}) y el algorimto REINFORCE (\cite{williams1992simple}) para actualizarlo. En general, este sistema modela el proceso de dise\~no autm\'atico de arquitecutras como un proceso de toma de decisiones secuencial, donde el estado de la red actual y la actuaci\'on es la operaci\'on de transformaci\'on correspondiente. Despue\'es de una cantidad determinada de pasos, la arquitectura resultante es evaludada para obtener la se\~nal de recompensa, que luego es utilizada para actualizar el meta-controlador, maximizando la validaci\'on.

        \paragraph*{NASNet (\cite{zoph2018learning})} Utiliza aprendizaje por refuerzo para aprender a construir la arquitectura de red neuronal \'optima para cualquier conjunto de im\'agenes. La contribuci\'on clave de esta propuesta es el dise√±o del espacio de b\'usqueda que permite construir la arquitectura en un dataset peque\~no y luego transferir los conocimientos para el entrenamiento de un set m\'as grande, aligerando el costo computacional de aplicarlo directamente.


% \section{M\'etodos de Gradiente}
% Los m\'etodos que utilzan esta estraetigan buscan calcular la direcci\'on del gradiente tal que se mejore el rendimiento de la soluci\'on inicial y evaluar nuevas soluciones en la vecindad de dicha direcci\'on. Cuando se tiene un espacio de b\'usqueda diferenciable el gradiente se puede calcular de forma exacta.

    % \paragraph*{DARTS} eso

\subsection{Modelos Constructivos}
Estos m\'etodos exploran el espacio de b\'usqueda con una forma estructurada pues se definen de antemano los posibles modelos y formas de combinarlos. Se establece un orden de evaluaci\'on de las soluciones y la b\'usqueda finaliza cuando todo el espacio ha sido explorado. Esta estrategia es \'util cuando el espacio de b\'usqueda es peque\~no y consta de modelos bien definidos, variados y con un buen rendimiento.

\paragraph{AutoGluon (\cite{erickson2020autogluon})} Realiza procesamiento de datos avanzados, aprendizaje profundo y ensamblaje de modelos multicapa. Reconoce autom\'aticamente el tipo de datos de cada columna para un procesaminto de datos robustos. Construye un ensemble multicapa  tomando como entrada la instancia de cada uno de los tipos de modelos predefinidos. Los modelo se entrena de forma secuencial y se a\~naden al ensemble. Para finalizar, se realiza un proceso de post-optimizaci\'on para destilar el ensemble resultante en un modelo m\'as peque\~no con rendimiento similar.

\subsection{Monte Carlo}
 Esta estrategia se emplea en espacios de b\'usquedas jer\'arquicos para explorar eficientemente el \'arbol que describe todas las  posibles soluciones. En cada iterac\'on se deciende por una rama del \'arbol hasta llegar a un nodo hoja, el camino representa una posible soluci\'on. Como es un algoritmo de MonteCarlo es necesario definir una funci\'on que permita un balance entre exploraci\'on y explotaci\'on. Esta estrategia require un espacio de b\'usequda donde las decisiones m\'as importantes esten al principio en el \'arbol para ser efectiva

 \paragraph{ML-Plan (\cite{mohr2018ml})} Un sistema novedoso basado en redes de tareas jer\'arquicas (HTN, \cite{erol1994umcp}). La b\'usqueda es aleatoria, construyendo flujos parciales junto con un mecanismo que evita el sobreajuste. Cuenta con con dos tipos de algoritmos:  preprocesadores de datos y de aprendizaje. Sus flujos son un par compuestos por un procesador parametrizado y por un algoritmo de aprendizaje.
    


\section{Optimizaci\'on Multiobjetivo}\label{proposal:moo}
Optimizaci\'on Multiobjetivo es la rama de la Ciencia y la Matem\'atica que se dedica a optimizar varias funciones objetivos sim\'ultaneamente. Es relativamente nueva y un campo activo de investigaci\'on. El problema multiobjetivo (PMO) se define como:
 
\begin{definition}{Optimizaci\'on Multibojetivo:}
     Dado $m$ funciones objetivos: $f_1: \mathcal{X} \rightarrow \mathbb{R}, ..., f_m: \mathcal{X} \rightarrow \mathbb{R}$ que dado un vector en el espacio de decisi\'on $\mathcal{X}$ es transformado en un valor de $\mathbb{R}$. Se define el PMO como:
    \begin{equation*}
        \min f_1(x), ..., f_m(x), x \in \mathcal{X}
    \end{equation*}
\end{definition}

Cuando se optimizan varias funciones, la mejor soluci\'on  no es un escalar, sino un vector y no necesariamente \'unico; pues al haber m\'as de dos medidas de evaluaci\'on un vector puede ser mejor que otro en ciertas m\'etricas pero no en todas. Para referirse a esto, en la literatura se le conoce como \textit{Pareto dominaci\'on}.

\begin{definition}{Pareto Dominaci\'on:}
    Dados dos vectores en el el espacio objetivo, $x \in \mathbb{R}^m$ y $z \in \mathbb{R}^m$, se dice que $x$ Pareto domina a $z$ (i.e. $x \prec z$), si y solo si:
    \begin{equation*}
        \forall i \in \{1, ..., m\}: x_i \leq z_i \text{ y } \exists j \in \{1, ..., m\}: x_j < z_j
    \end{equation*}
\end{definition}

Cuando se tiene un conjunto de vectores que nadie domina, es lo que se conoce como Frente de Pareto y es el conjunto soluci\'on del problema multiobjetivo.

\begin{definition}
    \textit{Frente de Pareto}: Todos los vectores $x$ del espacio objetivo $\mathcal{Y}$ tal que no exista $y \prec x$.
    \begin{align*}
        \mathcal{P} = \{x| x, y \in \mathcal{Y}, \neg \exists y \prec x \} 
    \end{align*}
\end{definition}

%TODO:
%Hablar sobre a priori, interactivo y a posteriori en la optimizacion multi objetivo?

El problema multiobjetivo ha encontrado uso en el campo de la ingenier\'ia y la econom\'ia donde los objetivos no se describen como mientras m\'as mejor, sino que se tiene un valor ideal para cada funci\'on objetivo y se quiere que todos se acerquen a esto lo m\'as posible. Cuando se produce energ\'ia se existe un trade of entre consumo  y combustible utilizado (\cite{shirazi2012thermal} y \cite{shirazi2014thermal})

Buscando un dise√±o \'optimo que maximice ciertos objetivos. Control Cabinet Layouot Optimization (\cite{pllana2019customizing}). Dise√±o de una granja solar (\cite{ganesan2013hypervolume})

Para la optimizacion de recursos de radio para satisfacer eficientemente el requerimiento de los usuarios (\cite{bjornson2013optimal})

Inspecci\'on en Infraestructura, donde en estructuras complejas no es factible una revision 100\% y se plantea un MOP donde se optimice para maximizar la covertura y minimzar los costos (\cite{ellefsen2017multiobjective})

% SPEA se utiliza en \cite{rafiei2009chaos}

El problema multiobjetivo ha tenido tres enfoques princiaples a lo largo del tiempo:
\begin{enumerate}
    \item T\'ecnicas de Escalarizaci\'on.
    \item M\'etodos Num\'ericos.
    \item Algoritmos Evolucionarios.
\end{enumerate}


% A√±adir problemas que se hayan resulto con multiobjetivo
% El objetvio es mostrar lo mucho que se ha usado multiobjetivo 
% Y lo poco que se ha utilizado en automl
% Decir que lo vamos a probar 

\subsection{T\'ecnicas de Escalarizaci\'on }

El problema multiobjetivo cl\'asicamente ha sido resuelto utilizando t\'ecnicas de escalarizaci\'on (\cite{miettinen2012nonlinear}). Esta t\'ecnica consiste  en agregar funciones objetivos o  reformularlas como restricciones para luego resolver el problema optimizando para un solo objetivo. La nueva funci\'on objetivo se parametriza con el objetivo de obtener distintos puntos del frente de Pareto en cada corrida.
\begin{enumerate}
    \item Linear Weighting: Todas las funciones objetivos se combinan en una sola, y a cada una se le asigna un peso. Modificando estos pesos se obtiene una soluci\'on distinta del frente de Pareto.
    \begin{equation*}
        \min \sum w_i f_i(x), \space x \in X
    \end{equation*}
    Se garantiza que una soluci\'on de esta nueva funci\'on objetivo siempre est\'a sobre el frente de Pareto  y si este es convexo se puede hallar cualquier punto de este con el correcto vector de peso(\cite{emmerich2018tutorial}). El problema yace cuando el frente de Pareto tiene forma c\'oncava donde \textit{Linear Weighting} resulta insuficiente por no ser capaz obtener los puntos de esta secci\'on del frente.

    \item $\epsilon$-constrain: Se selecciona una funci\'on objetivo como principal y las dem\'as se establecen como restricciones de esta tal que sean menor que sierto $\epsilon_i$ con $1 \leq n - 1$ por cada funci\'on objetivo.
    \begin{align*}
            \min  f_1(x), \space x \in X  & \text{, sujeto a:}   \\
            g_i(x) \leq \epsilon_i & \quad  \forall i, 2 \leq i \leq n
    \end{align*}
    Esta enfoque presenta dos dificultades principales: la valores de los $\epsilon_i$, para una adecuada selecci\'on requiren conocimiento previo del frente de Pareto y al igual que \textit{Linear Weighting}, no es capaz de detectar soluciones en las partes c\'oncavas del frente (\cite{emmerich2018tutorial}).

    % TODO: Que condicion cumple los pesos de Chebychev
\item Chebychev Distance (CSP): Se establece un punto de referencia $z^*$ y se utiliza la distancia de Chebychev de los vectores objetivos hacia este como funci\'on objetivo utilizando un vector de pesos $\lambda \in \mathbb{R}^m_{\prec 0}$, donde $\mathbb{R}^m_{\prec 0} = \{x | x \in \mathbb{R}^m, x \prec 0 \}$. 
    \begin{align*}
        \min \quad \max_{i \in {1,...,m}} \lambda_i |f_i(x) - z^*_i|, x \in X 
    \end{align*}
    CSP dado un punto de referencia y vector de pesos adecuados puede encontrar cualquier punto del frente de Pareto, no importa su forma (\cite{emmerich2018tutorial}).
\end{enumerate}

Recientemente escalarizaci\'on ha sido utilizado dentro de algoritmos gene\'eticos por descomposici\'on para buscar secciones definidas del frente de pareto.  En \cite{paria2020flexible} se propone un algorimto capaz de mappear un area determinada del frente de Pareto utilizando una estrategia basada en escalarizaci\'on aleatoria.


\subsection{Algoritmos Num\'ericos}

% TODO: Es esto verdad?
En principio todos los algoritmos de escalarizaci\'on se pueden resolver utilzando m\'etodos n\'umericos. Adem\'as existen otros m\'etodos  que intentan resolver el problema haciendo cumplir las condiciones de Karush-Kuhn-Tucker (KKT) definidas por \cite{kuhn2014nonlinear}.

La idea va de encontrar al menos una soluci\'on al sistema de ecuaciones creado tras intentar resolver el problema KKT. Luego se utilizan m\'etodos de continuaci\'on y homotop\'ia para a√±adir al conjunto soluci\'on soluciones cercanas a esta. 
Este tipo de enfoque no es ideal para espacios de b\'usqueda complejos pues requiere que las soluciones satisfagan las condiciones de convexidad local y diferenciabilidad. se puede obtener mas infomraci\'on en \cite{hillermeier2001nonlinear} y \cite{schutze_et_al:DagSemProc.04461.16}.

Tambien existen otros metodos para la b\'usqueda de m\'inimos globales como \textit{T\'ecnicas de Subdivisi\'on} por \cite{dellnitz2005covering}, \textit{Optimizaci\'on Global Bayesiana} por \cite{emmerich2016multicriteria} y \textit{Optimizaci\'on de Lipschitz} por \cite{vzilinskas2013worst}. % Estas requiren de que el espacio de decisi\'on tenga una baja dimensionalidad.

Adem\'as  se investiga  m\'etodos n\'umericos que no necesiten diferenciar para su resoluci\'on utilizando t\'ecnicas de b\'usquedas directas. Se pueden encontrar ejemplos de estos algoritmos en \cite{custodio2011direct} y \cite{audet2010mesh}.

\subsection{Algoritmos Evolucionarios Multiobjetivos }

Los algorimtos gen\'eticos utilizan paradigmas extra\'idos de la naturaleza, tal como selecci\'on natural, mutaci\'on y recombinaci\'on para dirigir una poblaci\'on (o conjunto de vectores de decisi\'on) hacia una soluci\'on \'optima (\cite{back1996evolutionary}).

Los algoritmos evolucionarios multiobjetivos (MOEA) generalizan esta idea, y son dise√±ados para acercarse en cada iteraci\'on  al frente de Pareto. Como en este caso no existe soluci\'on \'unica, la manera de selccionar los individuos cambia fundamentalmente. Dentro de los MOEA existen tres paradigmas principales:

\begin{enumerate}
    \item \textbf{MOEA basados en el frente de Pareto}\label{def:MOEA}: Se identifican por dividir el proceso de selecci\'on en dos etapas. En la primera se organizan los invidiuos segu\'un su ind\'ice de dominaci\'on y se acomodan en distintos subconjutnos seg\'un la cantidad de soluciones que los dominen (e.g. un subconjunto para las soluciones a las cuales nadie domina, otro para los son dominados por alguna soluci\'on etc.). En la segunda ordenaci\'on cada subconjunto se ordena buscando que los primeros lugares sean los elementos m\'as representativos de cada subconjunto. NSGA-II (\cite{deb2002fast}) y SPEA2 (\cite{zitzler1999multiobjective}) son algoritmos de este tipo.

    \item \textbf{Basados en indicador}: Estos utilizan un indicador para calcular cuan cercano es el conjunto actual al frente de Pareto (unario), o cuanto mejora el nuevo conjunto de soluciones respecto a la iteraci\'on anterior (binario). Ejemplo de este es SMS-EMOEA (\cite{emmerich2005emo}) que suele converger al frente de Pareto con soluciones igualmente distribuidas.

    \item \textbf{Basados en descomposici\'on}: La idea principal consiste en descomponer el problema en peque√±os subproblemas cada una correspondiente a una secci\'on del frente de Pareto. Por cada sub-problema se resuelve utilizando escalarizaci\'on con diferente paramtrizaci\'on. El m\'etodo de escalarizaci\'on m\'as usado en estos casos suele ser CSP debido a ser capaz de obtener cualquier punto del frente de Pareto. Ejemplo de este paradigma son MOEA/D (\cite{zhang2007moea}), NSGA-III (\cite{deb2013evolutionary}) y MOMSA (\cite{sharifi2021new}).

\end{enumerate}

% (Poner esto en alg\'un lado)
 El termino Optimizaci\'on Multiobjetivo se utiliza cuando el n\'umero de funciones objetivos son dos o tres. Para un cantidad de m\'etricas mayor se le conoce coloquialmente en la literatura como Optimizaci\'on para Muchos Objetivos o \textit{many-objective optimization} en ingl\'es, propuesto inicialmente por \cite{10.1007/978-3-540-31880-4_2}. Se hace enf\'asis en esta diferenciaci\'on pues al aumentar el n\'umero de m\'etricas a optimizar:
 \begin{enumerate}
     \item ya no es posible visualizar el frente obtenido;
     \item la computaci\'on de indicadores o de selecci\'on para muchos algoritmos se convierte en problemas NP-duros;
     \item existe un r\'apido crecimiento de puntos no dominados, mientras mayor n\'umero de objetivos, la probabilidad de que un punto sea no dominado en un set con distribuci\'on normal tiende exponencialmente a 1.
 \end{enumerate}

Los algoritmos que mejor han tenido resultado en esta \'area son los algoritmos basados en descomposci\'on.


\section{AutoML y Multiobjetivo}\label{proposal:mooautoml}
% En el campo del aprendizaje de m\'aqina han habido varias investigaciones respecto a la Optimizaci\'on Multibobjetivo.  An\'alisis de curva caracter\'istca de receptor (\textit{receiver operating characteristic curve}, ROC) de \cite{everson2006multi} para calcular el costo de clasificaciones err\'oneas de un clasificador mostrando gr\'aficamente un intercambio entre los verdaderos y falsos positvos de dos o m\'as problemas de clasificaci\'on utilizando Optimizaci\'on Multiobjetivo. 
% \cite{jin2008pareto} hacen un analisis sobre la adici\'on de optimizaci\'on multibojetivo al Aprendizaje de M\'aquina. Compara los diferentes enfoques de escalarizaci\'on y algoritmos gen\'eticos.
% En el campo de configuraci\'on de algoritmos \cite{blot2016mo} introduce un busqueda iterativa local basado en multiples criterios para configurar solucionadores SAT.

El estudio de optimizaci\'on en sistemas Aprendizaje de M\'aqina Automatizado es bastante escaso. Entre los sistemas AutoML que cuentan con esta caracter\'istica se encuentra es TPOT \cite{pmlr-v64-olson_tpot_2016} que optimiza mutuamente para exactitud y modelos de Aprendizaje de Maquina m\'as sencillos, no obstante estas m\'etricas est\'an fijas y el progrmador no puede modificarlas, ni a\~nadir m\'as.
En \cite{pfisterer2019multi} se propone una adici\'on a \textit{autoxgboost} (\cite{thomas2018automatic}) para optimizar multiobjetivo utilizando un algoritmo de simple de escalarizaci\'on. Esta implementaci\'on es flexible en cuanto a m\'etricas utilizar.

En AutoGOAL se propone la adici\'on de optimizar para varios objetivos utilizando un algorimto gen\'etico que est\'an demostrados que son resistentes a la forma del frente de Pareto. Los objetivos seri\'ian definidos por el usuario y la respuesta ser\'ia un conjunto de flujos de ML que estuvieran en el frente de Pareto.


