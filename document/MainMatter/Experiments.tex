\chapter{Experimentaci\'on y Resultados}\label{chapter:experiments}
En este cap\'itulo se eval\'uan los resultados obtenidos por AutoGOAL Multiobjetivo tras aplicarse sobre tres corpus de datos utilizando los pares de m\'etricas precisi\'on contra recobrado y \textit{f-score} contra tiempo de entrenamiento:
\begin{itemize}
    \item Precisi\'on es una m\'etrica que mide las muestras clasificadas correctamente entre todas las muestras extra\'idas.
    \item Recobrado mide las muestras clasificadas correctamente sobre todas las extra\'idas.
    \item \textit{F-score} es el promedio arm\'onico entre precisi\'on y recobrado.
    \item \textit{Tiempo de entrenamiento} es un estimado del tiempo que toma para una flujo de Aprendizaje Autom\'atico en realizar el proceso de entrenamiento.
\end{itemize}

Se utiliza el par de m\'etricas precisi\'on y recobrado pues son criterios que pueden tener comportamientos variados. Existen problemas donde es posible maximizar ambas y otros donde es obligatorio realizar concesiones entre estas tal que no exista una mejor soluci\'on sino un conjunto de estas.

Se utilza \textit{f-score} contra tiempo de entrenamiento para probar si es posible dirigir efectivamente  la b\'usqueda maximizando la relevancia y minimizando el tiempo de ejecuci\'on. Es posible utilzar tambi\'en precisi\'on y recobrado junto con tiempo de entrenamiento pero con el objetivo de mantener estos experimentos sencillos se utiliza \textit{f-score}.

\section{Corpus de Evaluaci\'on}
Se utilizan tres corpus de datos para comprobar el comportamiento del sistema cuando optimiza para varias m\'etricas simult\'aneamente. Los corpus se escogen de distintos tama√±os y cada uno representa versiones distintas del problema de aprendizaje supervisado.

\subsection{Cars}
Cars \brackcite{Dua:2019} es un corpus que representa un conjunto de carros con ciertas caracter\'isticas catalogadas cualitativamente (tabla \ref{implementation:table:cars:attributes}). El objetivo con este corpus es aprender a clasificar los carros de  acuerdo a sus atributos  en inaceptable, aceptable, bueno o muy bueno (tabla \ref{implementation:table:cars:classes}). El corpus no tiene valores desconocidos.

\begin{table}[ht]
    \centering
    \parbox{.45\linewidth}{
    \begin{tabular} { |l|c| }
        \hline
        Atributos & Valores \\
        \hline
        \hline
        buying & v-high, hihg, med, low \\
        \hline
        maintance &  v-high, hihg, med, low\\
        \hline
        doors & 2, 3, 4, 5-more\\
        \hline
        persons & 2, 4, more\\
        \hline
        lug\_boot & small, med, big\\
        \hline
        safety & low, med, high\\
        \hline
    \end{tabular}
    \caption{Tipos de Atributos en Cars}
    \label{implementation:table:cars:attributes}
    }
    \qquad
    \parbox[t]{.45\linewidth}{
    \begin{tabular} {|l|c|c|}
        \hline
        Clases & N & \% \\
        \hline
        \hline
        unacc & 1210 & 70.023\%\\
        \hline
        acc & 384 & 22.222\%\\
        \hline
        good & 69 & 3.993\%\\
        \hline
        v-good & 65 & 3.762\%\\
        \hline
    \end{tabular}
    \caption{Distribuci\'on de clases en Cars}
    \label{implementation:table:cars:classes}
    }
\end{table}

\subsection{HAHA}
Humor Analysis based on Human Annotation \brackcite{chiruzzo2019overview} representa un conjunto de datos que contiene \textit{tweets} en espa\~nol en texto plano codificado en utf-8. Se quiere construir un clasificador que pueda catalogarlos correctamente entre si son humor\'isticos o no. Contiene un total de 30000 tweets donde se utilizan 24000 para entrenamiento y 6000 para evaluaci\'on.

\begin{table}[ht]
    \centering
    \begin{tabular} {|l||c|c|c|}
        \hline
        & Entrenamiento & Evaluaci\'on & Total \\
        \hline
        \hline
        Tweets & 24000 & 6000 & $30000$\\
        \hline
        Graciosos & 9253 & 2342 & 11595\\
        \hline
        No graciosos & 14 757 & 3 658 & 18 405\\
        \hline
        Puntuaci\'on Promedio & 1305 & 275 & 1580\\
        \hline
    \end{tabular}
    \caption{Distribuci\'on de clases en HAHA}
    \label{implementation:table:haha}
\end{table}

\subsection{MEDDOCAN}

\textit{Spanish Clinical Case Corpus - Medical Document Anonymization} (MEDDOCAN) \brackcite{marimon2019automatic} representa una colecci\'on de 1000 casos cl\'inicos con anotaciones en formato BRAT \brackcite{stenetorp2012brat}. Cada caso cl\'inico est\'a codificado en utf-8 con con un promedio 33 oraciones o 495 palabras. El objetivo es procesar los casos cl\'inicos para predecir los anotaciones hechas.

\section{Hardware}
 Los experimentos fueron ejecutados en un equipo con las siguientes propiedades: CPU AMD R5 3550h y 32 GB de RAM.

\section{Resultados y An\'alisis}

En esta secci\'on se muestran los resultados obtenidos tras aplicar AutoGOAL Multiobjetivo a los distintos corpus. En las gr\'aficas solo se tiene en cuenta la puntuaci\'on de relevancia obtenida durante entrenamiento y no con respecto a los datos de prueba. Los puntos  grises marcan las mejores soluciones encontradas en cada generaci\'on.  La tonalidad de los puntos var\'ia de acuerdo en que iteraci\'on del algoritmo fue encontrado; a medida que avanzan las generaciones estos se oscurecen. Los puntos marcados con cruces rojas representan las mejores soluciones encontradas por el algoritmo y conforman una aproximaci\'on del frente de Pareto.

En cada conjunto de datos se utilizan par\'ametros distintos debido fundamentalmene a que cada corpus representa problemas de diferente complejidad y cantidad de datos.

\subsection{Cars}
La aplicaci\'on de AutoGOAL en Cars utiliza una poblaci\'on total de 40 individuos por generaci\'on, 1 hora de tiempo m\'aximo y 10 segundos de tiempo l\'imite por \textit{pipeline}. Se utilizan las implementaciones de \textit{f-score}, precisi\'on y recobrado de scikit-learn \brackcite{pedregosa2011scikit} con el promedio \textit{weighted} utilizado para problemas de clasificaci\'on multiclase que pueden tener un desbalance en las clases existentes.

\subsubsection{F-Score contra Tiempo de Entrenamiento}
La mayor\'ia de las soluciones encontradas componen un frente de Pareto con una forma extra\~na aparentemente c\'oncava pero bien distribuida sobre el espacio (figura \ref{impl:fig:cars:fscore_vs_time}). Las soluciones encontradas cuentan con un \textit{f-score} superior a 0.8. Mientras aumenta el f-score de las soluciones aumenta tambi\'en el tiempo de entrenamiento.

Los algoritmos que logran una puntuaci\'on de 1.0 tienen en com\'un que todos utilizan \textit{Suppport Vector Classification} (SVC). En el rango de 0.7 a 0.9 se encuentran pipelines con distintas t\'ecnicas como \textit{Nearest Centroid}, \textit{Multinomial Naive Bayes}, \textit{Bernoulli Naive Bayes} y SVC l\'ineal.

\begin{figure}[ht]
    \centering
    \includegraphics[scale=0.65]{Pictures/cars_fscore_vs_time.jpg}
    \caption{Cars: F-score contra Tiempo de Entrenamiento}
    \label{impl:fig:cars:fscore_vs_time}
\end{figure}


\subsubsection{Precisi\'on contra Recobrado}
Durante esta experimento  ni precisi\'on ni recobrado entran en conflicto y por tanto no es necesario hacer concesiones entre una o la otra durante la optimizaci\'on. Se puede observar en la figura \ref{impl:fig:cars:precision_vs_recall} que el frente de Pareto esta constituido por un solo punto donde se maximizan precisi\'on y recobrado. Se observa tambi\'en la mejor\'ia gradual de las soluciones seg\'un el transcurso de las iteraciones. 

AutoGOAL encontr\'o 5 soluciones con una t\'ecnica de SVC con un rendimiento perfecto. En este caso hay flujos m\'as complejos con respecto a la experimento anterior pues no se discrimina por tiempo de entrenamiento.

\begin{figure}[ht]
    \centering
    \includegraphics[scale=0.65]{Pictures/cars_precision_vs_recall.jpg}
    \caption{Cars: Precisi\'on contra Recobrado}
    \label{impl:fig:cars:precision_vs_recall}
\end{figure}

\subsection{HAHA}
Se utilizo una poblaci\'on total de 40 individuos, 8 horas de tiempo m\'aximo y 10 segundos por  evaluaci\'on. 
HAHA es un problema de clasificaci\'on binario y las m\'etricas \textit{f-score}, precisi\'on y recobrado son las implementadas en scikit-learn \brackcite{pedregosa2011scikit} utilizando promedio binario.

\subsubsection{F-Score contra Tiempo de Entrenamiento}

En esta experimento el frente obtenido (fig. \ref{impl:fig:haha:fscore_vs_time}) posee una forma aparentemente similar al de Cars (fig. \ref{impl:fig:cars:fscore_vs_time}). Los soluciones de AutoGOAL  est\'an conformados por dos algoritmos principales. Los que contienen una precisi\'on sobre los 0.5 con el menor tiempo de entrenamiento  utilizan t\'ecnicas de \textit{Hashing Vectorizer} y \textit{Nearest Centroid} mientras que los de mayor precisi\'on y mayor tiempo de entrenamiento est\'an a  compuestos por \textit{CountVectorizer}  y regresores log\'isticos.

En la esquina superior izquierda se ve como AutoGOAL busca soluciones que tienen \textit{f-score} 0, un desperdicio de tiempo de c\'omputo pues el sistema es agn\'ostico al significado de las m\'etricas. Una posible mitigaci\'on a esto es definir no solo las m\'etricas a evaluar si no establecer relaciones entre estas tal como: \textit{if f-score} $== 0 \rightarrow $ \textit{retorna} $-\infty$. Estas restricciones reducen el espacio objetivo y tienen un impacto directo en la b\'usqueda dando a\'un m\'as expresividad a los usuarios de AutoGOAL.

\begin{figure}[ht]
    \centering
    \includegraphics[scale=0.65]{Pictures/haha_fscore_vs_time.jpg}
    \caption{HAHA: F-score contra Tiempo de Entrenamiento (10 segundos m\'ax)}
    \label{impl:fig:haha:fscore_vs_time}
\end{figure}

Se debe resaltar que hay algoritmos que toman 10 segundos para su ejecuci\'on y posiblemente las soluciones del sistema se vean limitadas por el tiempo m\'aximo asignado a cada \textit{pipeline}. Se realiza un segundo experimento extendiendo esta restricci\'on hasta 3 minutos con el fin de verificar si aumentando el espacio de objetivo se puede obtener una representaci\'on distinta del frente de Pareto. En este caso la estructura extra\~na del frente se mantiene excepto por la aparici\'on de una nueva soluci\'on que destaca sobre el resto con un \textit{f-score} de 0.76 pero con un tiempo de entrenamiento de 31 segundos utilizando un \textit{Count Vectorizer} sin tokenizar y un  clasificador  de gradiente de descenso estoc\'astico (SGD por sus siglas en ingl\'es).

\begin{figure}[ht]
    \centering
    \includegraphics[scale=0.65]{Pictures/haha_fscore_vs_time_3min.jpg}
    \caption{HAHA: F-score contra Tiempo de Entrenamiento (3 minutos m\'ax)}
    \label{impl:fig:haha:fscore_vs_time_3min}
\end{figure}

\subsubsection{Precisi\'on contra Recobrado}
Contrario a lo que muestra la evaluaci\'on de Cars con respecto a precisi\'on y recobrado (fig \ref{impl:fig:cars:precision_vs_recall}), durante esta experimento no es posible encontrar un flujo que maximice ambas m\'etricas y es necesario hacer concesiones entre una y la otra. El frente tiene una forma convexa (fig. \ref{impl:fig:haha:precision_vs_recall}), consecuencia de las concesiones hechas debido al conflicto de intereses existente entre estas m\'etricas en este conjunto de datos.

Los flujos obtenidos durante la ejecuci\'on de esta fase presentan mucha mayor diversidad con respecto a todas las experimentos anteriores. Los flujos est\'an compuesto en su mayor\'ia por una tupla de t\'ecnicas de Aprendizaje: un m\'etodo de vectorizaci\'on y un clasificador.

\begin{figure}[ht]
    \centering
    \includegraphics[scale=0.65]{Pictures/haha_precision_vs_recall.jpg}
    \caption{HAHA: Precisi\'on contra Recobrado (10 segundos m\'ax)}
    \label{impl:fig:haha:precision_vs_recall}
\end{figure}

Cuando se optimiza con tiempo m\'aximo de tres minutos (fig. \ref{impl:fig:haha:precision_vs_recall_3min}) no se muestra ning\'un cambio notable con respecto al experimento anterior. 

\begin{figure}[ht]
    \centering
    \includegraphics[scale=0.65]{Pictures/haha_precision_vs_recall_3min.jpg}
    \caption{HAHA: Precisi\'on contra Recobrado (3 minutos m\'ax)}
    \label{impl:fig:haha:precision_vs_recall_3min}
\end{figure}

\subsection{MEDDOCAN}
Este corpus representa el conjunto de datos m\'as grande de los tres y  fue necesario aumentar el tiempo de evaluaci\'on por flujo a 10 minutos con el fin de encontrar soluciones v\'alidas, estas tomando tiempos de entre 2 y 6 minutos. Los experimentos fueron ejecutadas con una poblaci\'on total de 50 individuos, 10 horas de tiempo m\'aximo y 10 minutos por evaluaci\'on. 
Se utilizan las implementaciones de \textit{f-score}, precisi\'on y recobrado del m\'odulo de Python \textit{meddocan}.
Los entrenamientos durante esta evaluaci\'on resultaron ser m\'as lentos y no fue posible realizar muchas iteraciones por lo que no es posible tener una representaci\'on adecuada del frente de Pareto.
% Aqu\'i el tiempo m\'aximo es mucho mayor pues es un corpus es mucho m\'as grande que los anteriores que para encontrar al menos un pipeline v\'alido require alrededor de 7 u 8 minutos. Lo suficiente para lograr 3 o 4 generaciones de un total de 100.


\subsubsection{F-Score contra Tiempo de Entrenamiento}
En esta experimento se ve un comportamiento similar a las anteriores como puede observar en la figura  \ref{impl:fig:MEDDOCAN:fscore_vs_train_time} excepto que las concesiones hechas se tornan m\'as grave respecto a la m\'etrica de tiempo de entrenamiento pues la diferencia pasa de ser de segundos a minutos. Existe una soluci\'on con un tiempo de 160 segundos y una precisi\'on de 0.83 contra una de 230 segundos y una precisi\'on cercana a 0.9. Hay variedad de t\'ecnicas y tama\~no en los flujos generados .


\begin{figure}[ht]
    \centering
    \includegraphics[scale=0.65]{Pictures/meddocan_fscore_vs_train.jpg}
    \caption{MEDDOCAN: F-Score contra Tiempo de Entrenamiento}
    \label{impl:fig:MEDDOCAN:fscore_vs_train_time}
\end{figure}


\subsubsection{Precisi\'on contra Recobrado}
Esta evaluaci\'on (fig. \ref{impl:fig:MEDDOCAN:precision_vs_recall}), debido a la poca cantidad de iteraciones realizadas, se obtiene una representaci\'on pobre del frente de Pareto. No queda claro si se est\'a frente a un caso parecido al de precisi\'on contra recobrado de Cars (fig. \ref{impl:fig:cars:precision_vs_recall}) donde las m\'etricas no entran en conflicto y es posible optimizar para ambas, o mas parecido al caso en HAHA (fig. \ref{impl:fig:haha:precision_vs_recall}) donde es obligatorio realizar concesiones.

En comparaci\'on a a el experimento anterior (fig. \ref{impl:fig:MEDDOCAN:fscore_vs_train_time}) donde se optimiza \textit{f-score} contra tiempo de entrenamiento est\'a realiz\'o menos iteraciones bajo las mismas condiciones, visible por la menor cantidad de puntos graficados. Esto sugiere que al optimizar utilizando el tiempo como una m\'etrica el sistema prioriza flujos r\'apidos de entrenar afectando positivamente la velocidad de b\'usqueda general de AutoGOAL.

\begin{figure}[ht]
    \centering
    \includegraphics[scale=0.65]{Pictures/meddocan_precision_vs_recall.jpg}
    \caption{MEDDOCAN: Precisi\'on contra Recobrado}
    \label{impl:fig:MEDDOCAN:precision_vs_recall}
\end{figure}
