\chapter{Propuesta}\label{chapter:proposal}

\section{Probabilistic Grammatic Evolution}

Algoritmos evolucionarios estan sutilmente inspirados por las ideas de Evoluci\'on Natural, donde una selecci\'on de invdividuos evoluciona a traves de una aplicaci\'on de operadores como selecci\'on, mutaci\'on y recombinaci\'on. La calidad de estos individuos se evaluan en contra de una m\'etrica de evaluacion. Tras aplicar los operadores e ir reteniendo los individuos con m\'as aptos se espera que la poblacion mejore en sucesivas iteraciones.

\subsection{GE}
Con esta idea en mente nace Grammatical Evolution, que utiliza una gramatica para establecer restricciones sint\'acticas sobre las soluciones individuales. Introudce la distinci\'on entre el genotipo y el fenotipo. 

Para obtener una soluci\'on se tienen el genotipo (usualmente una lista de enteros) que se mapea al fenotipo (una lista de prdoucciones) siguiendo las reglas de producci\'on en una Gram\'atica Libre del Contexto (\textit{Context-Free Grammar}, CFG). Donde una gramatica es una terna $G = (NT, T, S, P)$ donde $NT$ y $T$ representan los conjuntos disjuntos no vac\'io de los s\'imbolos no terminales y terminales respectivamente. $S$ es un elemento de $NT$ llamado el axioma que representa el no-terminal principal que expandiendo este se puede llegar a todas las posibles formas de la gramatica. $P$ es el conjunto de reglas de producci\'on que rigen a la grma\'atica. Las reglas en $P$ tienen la forma de $A ::= \alpha$, donde $A \in NT$ y  $\alpha \in (NT \cup F)^*$ 

% Insertar ejemplo de como funciona esta talla

El rendimiento de GE ha sido criticado en la literatura por tener alta redundancia y poca localidad. Una representaci\'on tiene alta redundancia cuando varios genotipos corresponden al mismo fenotipo y localidad se refiere a como los cambios en el genotipo se refeljean en el fenotipo. Con el objetivo de mejora GE han exisitido varias propuestas. Una de esta es Evoluci\'on de Gram\'atica Probabilistica.


\subsection{PGE}
 (\textit{Probabilistic Grammatic Evolution}).

% En PGE se propone un cambio de como se interpreta el genotipo, ya no es una lista de enteros, sino u

Utiliza Algirmtos de Estimacion de Distribucion (\textit{Estimation of Distribution Algorithms, EDA}) una t\'ecninca probabi\'istica que remplaza los operadores de mutaci\'on y cruce por un sampleando sobre la probabiliad de distribuci\'on de las producciones obtenidas por mejor individuo, para luego generar una nueva poblaci\'on por cada cada generaci\'on. Las probabilidades comienzan todas inicializadas en igual proporci\'on  y se actualizan basado en la frecuencia de las reglas de produccion escogidas para obtener el individuo con el mayor rendimiento.

Probablisitic Grammatical Evolution (PGE)  se apoya en una Gramatica Probabilistica Libre del Contexto (\textit{Probilistic Context-Free Grammatic Evolution} PCFGE) para realizar los mapeos de los fenotipos a los genotipos. PCFGE se establece como una tupla $PG = (NT, T, S, P, Prob)$ donde $Prob$  es un conjunto de probabilidades asocaido con cada regla de la gram\'atica. El genotipo en PGE es un vector de numeros fraccionarios, donde cada uno corresponer con la probabiliad de seleccion cierta regla de derivaci\'on.

insetar ejemplo de PGE.

En PGE las probabilidades se actualizan despues de cada generaci\'on  despues de evaluar la poblaci\'on generada, basasdo en cuantas veces cada regla de derivacion fue seleccionada por el el individuo de mejor rendimiento. Si la regla fue seleccionada su probablidad incrementa, en cambio si no, su probabilidad se reduce. Alternando entre estas dos variantes se ayuda a evitar usar el mismo individuo en iteraciones consecutivas, balanceando exploracion global con expotacion local.

\section{Nodominated Sorting Genetic Algorithm II (NSGA-II)}

\begin{figure}
    \includegraphics[width=\linewidth]{Pictures/nsga2.png}
    \label{nsga2}
\end{figure}

El funcinamiento general de NSGA-II es dado una poblacion ordenarlos, luego escoger los mejores $N$ individuos de dicha poblaci\'on y se genera una nueva poblacion con $2N$ individuos y se repiten los pasos.

La parte tocada de NSGA-II es en la manera en que ordena los elementos, que se divide en dos fases.

En la primera fase ordena las soluciones seg\'un las solucioens que las dominen, a traves de frentes de paretos de distinto rango. En primer lugar van las funciones que nadie domina, seria el frente de pareto de rango 0, las que domina al menos uno, el frente de pareto de rango 1, y as\'i sucesivamente.

Una vez se tenga esta ordenaci\'on se cogen los primero N soluciones para construir una nueva poblaci\'on a partir de esta utilizando un algoritmo gen\'etico. En el caso de que haya que picar por la mitad algun frente de rango K, es necesario utilizar otro metodo de ordenaci\'on. El objetivo final es obtener del frente de rango K la muestra mas representativa.

Para eso se propone Crowding distance:
Que calcula una estimasion de la densidad de las soluciones vecinas a cierta soluci\'on. Se calucla el promedio de la distancia de estos dos puntos cercanos al punto por cada funci\'on objetivo. Esta distancia sirve como un estimado del permitro del cuboide formado usando los vecinos m\'as cercanos como v\'ertices. 

El calculo de la distancia necesita ordenar la poblacion de acuerdo a cada funcion objetivo en orden ascendiente. Las puntos de menor y mayor con respecto a una funci\'on objetivo son asignados $\infty$. Todas las soluciones intermedias son asignadas las distancias iguales a la diferencia absoulta normalizada de los valores de la funcion de dos puntos adyacentes. Este calculo se hace sobre todas las funciones objetivo. El crowding distance es calculado como la suma de cada distancia indivual correspondiendo a cada funci\'on objetivo.

\begin{algorithm*}\caption{Crowding Distance}
    l = |S|

    for i = 0 to l:

    \quad set S[i].distance = 0

    for each objective $m$

    \quad S = sort(S, m)

    \quad S[0].distance = S[l].distance = $\infty$

    \quad for i = 2 to (l - 1):

    \qquad 
    \begin{math}
        S[i].distance  = \frac{S[i].distance + (S[i + 1].m - I[i - 1].m)}{f^{max}_{m} - f^{min}_m}
    \end{math}
\end{algorithm*}


\section{Autogoal con NSGA-II y PGE}

En el caso de AutoGOAL se a√±ade la busqueda NSPGE inspirada en NSGAII, donde se modifican a la hora de buscar los indices para actualizar la gramatica, se cogen a los N mejores utilizando los ordenamientos previamente mencionados. Es el cambio fundmental


